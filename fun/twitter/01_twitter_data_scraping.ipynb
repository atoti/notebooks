{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Twitter\n",
    "\n",
    "In this notebook, we make use of [Tweepy](https://www.tweepy.org/) to download tweets from [Twitter](https://twitter.com/).  \n",
    "Do note that at the point of creating this notebook, Twitter API is transiting to v2.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.9.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweepy.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the data that we are going to capture from the downloaded tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df():\n",
    "    return pd.DataFrame(\n",
    "        columns=[\n",
    "            \"tweet_id\",\n",
    "            \"name\",\n",
    "            \"screen_name\",\n",
    "            \"retweet_count\",\n",
    "            \"text\",\n",
    "            \"mined_at\",\n",
    "            \"created_at\",\n",
    "            \"favourite_count\",\n",
    "            \"hashtags\",\n",
    "            \"status_count\",\n",
    "            \"followers_count\",\n",
    "            \"location\",\n",
    "            \"source_device\",\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter developer account and authentication\n",
    "\n",
    "Before starting out, remember to get a [Twitter developer account](https://developer.twitter.com/en/docs/apps/overview) from its [Developer portal](https://developer.twitter.com/en) if you haven't.  \n",
    "Refer to the [Twitter API documentation](https://developer.twitter.com/en/docs/authentication/oauth-1-0a) on how to get the access tokens to be set under the `twitter_keys` below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [standard search API](https://developer.twitter.com/en/docs/twitter-api/v1/tweets/search/overview) from Twitter API v1.1 searches against sampling of recent Tweets published in the past 7 days. This will be replaced by the [recent search](https://developer.twitter.com/en/docs/twitter-api/tweets/search/introduction) endpoint in v2.  \n",
    "\n",
    "This search is not exhausive. Alternatively, if you have the tweet id, you can always pass the array of id to [`api.statuses_lookup()`](http://docs.tweepy.org/en/v3.5.0/api.html#API.statuses_lookup) to retrieve the historical tweets. You can find the list of tweets used in this series of notebook [here](https://s3.eu-west-3.amazonaws.com/data.atoti.io/notebooks/twitter/tweets_sentiments.csv) alongside with the sentiments at the point of data collection.\n",
    "Remember to set `wait_on_rate_limit` to true so that exception won't be thrown when the rate limits are hit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetMiner(object):\n",
    "\n",
    "    result_limit = 20\n",
    "    data = []\n",
    "    api = False\n",
    "\n",
    "    twitter_keys = {\n",
    "        \"consumer_key\": \"<To be replace>\",\n",
    "        \"consumer_secret\": \"<To be replace>\",\n",
    "        \"access_token_key\": \"<To be replace>\",\n",
    "        \"access_token_secret\": \"<To be replace>\",\n",
    "    }\n",
    "\n",
    "    def __init__(self, keys_dict=twitter_keys, api=api):\n",
    "\n",
    "        self.twitter_keys = keys_dict\n",
    "\n",
    "        auth = tweepy.OAuthHandler(\n",
    "            keys_dict[\"consumer_key\"], keys_dict[\"consumer_secret\"]\n",
    "        )\n",
    "        auth.set_access_token(\n",
    "            keys_dict[\"access_token_key\"], keys_dict[\"access_token_secret\"]\n",
    "        )\n",
    "\n",
    "        self.api = tweepy.API(\n",
    "            auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True\n",
    "        )\n",
    "        self.twitter_keys = keys_dict\n",
    "\n",
    "    def mine_crypto_currency_tweets(self, query=\"BTC\"):\n",
    "\n",
    "        last_tweet_id = False\n",
    "        page_num = 1\n",
    "\n",
    "        data = get_df()\n",
    "        cypto_query = f\"#{query}\"\n",
    "        print(\" ===== \", query, cypto_query)\n",
    "        for page in tweepy.Cursor(\n",
    "            self.api.search,\n",
    "            q=cypto_query,\n",
    "            lang=\"en\",\n",
    "            tweet_mode=\"extended\",\n",
    "            count=200,  # max_id=1295144957439690000\n",
    "        ).pages():\n",
    "            print(\" ...... new page\", page_num)\n",
    "            page_num += 1\n",
    "\n",
    "            for item in page:\n",
    "                mined = {\n",
    "                    \"tweet_id\": item.id,\n",
    "                    \"name\": item.user.name,\n",
    "                    \"screen_name\": item.user.screen_name,\n",
    "                    \"retweet_count\": item.retweet_count,\n",
    "                    \"text\": item.full_text,\n",
    "                    \"mined_at\": datetime.datetime.now(),\n",
    "                    \"created_at\": item.created_at,\n",
    "                    \"favourite_count\": item.favorite_count,\n",
    "                    \"hashtags\": item.entities[\"hashtags\"],\n",
    "                    \"status_count\": item.user.statuses_count,\n",
    "                    \"followers_count\": item.user.followers_count,\n",
    "                    \"location\": item.place,\n",
    "                    \"source_device\": item.source,\n",
    "                }\n",
    "\n",
    "                try:\n",
    "                    mined[\"retweet_text\"] = item.retweeted_status.full_text\n",
    "                except:\n",
    "                    mined[\"retweet_text\"] = \"None\"\n",
    "\n",
    "                last_tweet_id = item.id\n",
    "                data = data.append(mined, ignore_index=True)\n",
    "\n",
    "            if page_num % 180 == 0:\n",
    "                date_label = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                print(\"....... outputting to csv\", page_num, len(data))\n",
    "                data.to_csv(f\"{query}_{page_num}_{date_label}.csv\", index=False)\n",
    "                print(\"  ..... resetting df\")\n",
    "                data = get_df()\n",
    "\n",
    "        date_label = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        data.to_csv(f\"{query}_{page_num}_{date_label}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miner = TweetMiner()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the cryptocurrency hashtags that will be used to query. We have the option of combining query but in this case, we download the tweets for each cryptocurrency separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_list = [\n",
    "    \"ADA\",\n",
    "    \"BSV\",\n",
    "    \"LTC\",\n",
    "    \"LINK\",\n",
    "    \"BNB\",\n",
    "    \"BTC\",\n",
    "    \"ETH\",\n",
    "    \"XRP\",\n",
    "    \"USDT\",\n",
    "    \"BCH\",\n",
    "    \"EOS\",\n",
    "    \"TRON\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created threads to queue the mining of the cryptocurrency so that it can run unmanned for 10 iterations.  \n",
    "Since the tweets are sampled, we figured we should repeat the mining to gather as much data as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "import threading\n",
    "\n",
    "should_publish = threading.Event()\n",
    "update_queue = queue.Queue()\n",
    "\n",
    "\n",
    "def start_publisher():\n",
    "    global handle_list\n",
    "\n",
    "    starttime = time.time()\n",
    "    print(\"Start polling\", starttime)\n",
    "    poll_iteration = 1\n",
    "\n",
    "    for i in range(10):\n",
    "        for name in handle_list:\n",
    "            print(i, poll_iteration, \"\\rpublishing update \", end=\"\")\n",
    "            update_queue.put((poll_iteration, name))\n",
    "            poll_iteration += 1\n",
    "            time.sleep(900)\n",
    "            print(\"\\rawaiting for publishing update\", end=\"\")\n",
    "            should_publish.wait()\n",
    "            update_queue.join()\n",
    "\n",
    "\n",
    "def start_update_listener():\n",
    "    while True:\n",
    "        poll_iteration, name = update_queue.get()\n",
    "\n",
    "        print(\" --- \", name)\n",
    "        try:\n",
    "\n",
    "            miner.mine_crypto_currency_tweets(query=name)\n",
    "            update_queue.task_done()\n",
    "\n",
    "        except Exception as e:  # work on python 3.x\n",
    "            print(\"Failed to upload to ftp: \" + str(e))\n",
    "\n",
    "listener_thread = threading.Thread(target=start_update_listener, daemon=True)\n",
    "publisher_thread = threading.Thread(target=start_publisher, daemon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publisher_thread.start()\n",
    "listener_thread.start()\n",
    "# start publishing\n",
    "should_publish.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to stop the data polling before the 10 iterations end, run the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pause publishing\n",
    "should_publish.clear()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
