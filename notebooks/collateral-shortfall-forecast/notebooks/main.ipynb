{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collateral Shortfall Forecast\n",
    "\n",
    "This notebook is derived from a previous one available on our website around [Collateral optimization](https://github.com/atoti/notebooks/blob/master/notebooks/collateral-shortfall-monitoring/main.ipynb). For context, we’re copying here the first part of this notebook by [Hui Fang Yeo](https://www.linkedin.com/in/huifang-yeo/). The scenario starts diverging at the ‘What-If’ stage to integrate predictive machine learning algorithms. Jump to that part if you are already familiar with the use case.\n",
    "\n",
    "For more context and definitions around collateral shortfall monitoring, [check out our article on atoti.io](https://www.atoti.io/rapid-collateral-modelling-and-simulation-with-atoti/).\n",
    "\n",
    "### Introduction\n",
    "\n",
    "In this notebook, we will showcase how quickly a dashboard can be put together for a simplified use case of Collateral Shortfall monitoring with atoti libraries.  \n",
    "  \n",
    "Collateral is a form of credit risk mitigation where an asset is accepted as security for extending a loan.  \n",
    "Market value of a collateral changes over time and lender has to accomodate for it. As such, depending on the amount of risk associated, a percentage of what is known as haircut is applied to the asset's market value. This gives the value of the collateral that can be used for loan, also known as collateral value.   \n",
    "  \n",
    "Collateral Shortfall occurs when the collateral value goes below the cash out value. That meant that the value of collateral is less than what it is expected to be, due to a variety of factors such as market fluctuations, contracts enforceability etc. \n",
    "\n",
    "We will be creating a multi-dimension data cube and derive the various measures such as market value, collateral value after haircut, cash out value over account and thereafter, the Collateral shortfall for the accounts. \n",
    "\n",
    "Leveraging on the data cube and atoti's data visualization, we will put together dashboards that reflects collateral status of accounts. Cherry on top, we will perform some *What if Analysis* based on price simulation to demonstrate the impact on Collateral in the below scenarios:  \n",
    "\n",
    "- Asset price forecast at 1-day horizon\n",
    "- Asset price forecast at 3-days horizon\n",
    "- Asset price forecast at 1-week horizon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\" ><a href=\"https://www.atoti.io/?utm_source=gallery&utm_content=collateral-monitoring\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://data.atoti.io/notebooks/banners/discover.png\" alt=\"Try atoti\"></a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies\n",
    "\n",
    "As data used in this notebook is stored on AWS S3, hence it is necessary to install the [atoti-aws plugin](https://docs.atoti.io/latest/plugins.html#available-plugins).\n",
    "\n",
    "```\n",
    "!pip install atoti-aws\n",
    "or \n",
    "!conda install atoti-aws\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import atoti as tt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import utils\n",
    "from natsort import natsorted\n",
    "from sklearn.metrics import explained_variance_score, mean_squared_error, r2_score\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a session has to be created for atoti\n",
    "# dashboards are persisted in the content storage\n",
    "session = tt.Session(user_content_storage=\"./content\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading\n",
    "A session is used to read data of formats csv, parquet, pandas dataframe, numpy and spark.   \n",
    "Refer to https://docs.atoti.io/0.3.1/tutorial/08-data-sources.html \n",
    "   \n",
    "#### Loading csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Quantity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Account</th>\n",
       "      <th>Asset_Code</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Niel</th>\n",
       "      <th>CAP.PA</th>\n",
       "      <td>100000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAN.PA</th>\n",
       "      <td>100000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Musk</th>\n",
       "      <th>ENI.PA</th>\n",
       "      <td>100000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENGI.PA</th>\n",
       "      <td>100000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bezos &amp; MacKenzie</th>\n",
       "      <th>AC.PA</th>\n",
       "      <td>100000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Quantity\n",
       "Account           Asset_Code          \n",
       "Niel              CAP.PA      100000.0\n",
       "                  SAN.PA      100000.0\n",
       "Musk              ENI.PA      100000.0\n",
       "                  ENGI.PA     100000.0\n",
       "Bezos & MacKenzie AC.PA       100000.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asset_positions_table = session.read_csv(\n",
    "    \"s3://data.atoti.io/notebooks/collateral-shortfall-monitoring/assets_positions.csv\",\n",
    "    keys=[\"Account\", \"Asset_Code\"],\n",
    "    table_name=\"asset_positions\",\n",
    ")\n",
    "asset_positions_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sector</th>\n",
       "      <th>Country</th>\n",
       "      <th>Haircut</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asset_Code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BNP.PA</th>\n",
       "      <td>Financial Services</td>\n",
       "      <td>France</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA.PA</th>\n",
       "      <td>Consumer Defensive</td>\n",
       "      <td>France</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AC.PA</th>\n",
       "      <td>Consumer Cyclical</td>\n",
       "      <td>France</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENGI.PA</th>\n",
       "      <td>Utilities</td>\n",
       "      <td>France</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAP.PA</th>\n",
       "      <td>Technology</td>\n",
       "      <td>France</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Sector Country  Haircut\n",
       "Asset_Code                                     \n",
       "BNP.PA      Financial Services  France      0.1\n",
       "CA.PA       Consumer Defensive  France      0.1\n",
       "AC.PA        Consumer Cyclical  France      0.1\n",
       "ENGI.PA              Utilities  France      0.1\n",
       "CAP.PA              Technology  France      0.1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assets_table = session.read_parquet(\n",
    "    \"s3://data.atoti.io/notebooks/collateral-shortfall-monitoring/assets_attributes.parquet\",\n",
    "    keys=[\"Asset_Code\"],\n",
    "    table_name=\"assets\",\n",
    ")\n",
    "assets_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading csv via pandas before session loads pandas dataframe   \n",
    "Being able to load pandas dataframe gives us the flexibility to manipulate dataframe before loading them or later on when we do simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/assets-prices-test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/p5/t0t3kgq531340_t8gvllvm2m0000gn/T/ipykernel_14585/118852178.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0massets_prices_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"assets-prices-test.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0massets_prices_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/notebooks-6o2JMVq4-py3.9/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/notebooks-6o2JMVq4-py3.9/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/notebooks-6o2JMVq4-py3.9/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/notebooks-6o2JMVq4-py3.9/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/notebooks-6o2JMVq4-py3.9/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1218\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/notebooks-6o2JMVq4-py3.9/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    790\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/assets-prices-test.csv'"
     ]
    }
   ],
   "source": [
    "assets_prices_df = pd.read_csv(os.path.join(\"../data\", \"assets-prices-test.csv\"))\n",
    "assets_prices_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's transform the dataframe in order to obtain the desired shape: we want to have all the asset names in one column, and all their prices in anotehr column.\n",
    "\n",
    "To achieve that, we use the ***melt()*** method of the Pandas Dataframe class, available in the Pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_prices_df = assets_prices_df.melt(\n",
    "    id_vars=\"Date\", var_name=\"Asset_Code\", value_name=\"Price\"\n",
    ").set_index([\"Asset_Code\", \"Date\"])\n",
    "assets_prices_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_prices_table = session.read_pandas(\n",
    "    assets_prices_df,\n",
    "    keys=[\"Asset_Code\", \"Date\"],\n",
    "    table_name=\"assets_prices\",\n",
    ")\n",
    "assets_prices_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_positions_df = pd.read_csv(\n",
    "    \"http://data.atoti.io/notebooks/collateral-shortfall-monitoring/loans_positions.csv\"\n",
    ")\n",
    "loans_positions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_positions_table = session.read_pandas(\n",
    "    loans_positions_df, keys=[\"Account\"], table_name=\"loans_positions\"\n",
    ")\n",
    "loans_positions_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining data table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_positions_table.join(assets_table, mapping={\"Asset_Code\": \"Asset_Code\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_positions_table.join(loans_positions_table, mapping={\"Account\": \"Account\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_positions_table.join(assets_prices_table, mapping={\"Asset_Code\": \"Asset_Code\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cube creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube = session.create_cube(asset_positions_table, \"Collateral_Management\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick analysis with cube.visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "atoti": {
     "widget": {
      "mapping": {
       "columns": [
        "ALL_MEASURES"
       ],
       "measures": [
        "[Measures].[Quantity.SUM]"
       ],
       "rows": [
        "[asset_positions].[Account].[Account]",
        "[assets].[Sector].[Sector]",
        "[asset_positions].[Asset_Code].[Asset_Code]"
       ]
      },
      "query": {
       "mdx": "SELECT NON EMPTY {[Measures].[Quantity.SUM]} ON COLUMNS, NON EMPTY Crossjoin(Hierarchize(Descendants({[asset_positions].[Account].[AllMember]}, 1, SELF_AND_BEFORE)), Hierarchize(Descendants({[assets].[Sector].[AllMember]}, 1, SELF_AND_BEFORE)), Hierarchize(Descendants({[asset_positions].[Asset_Code].[AllMember]}, 1, SELF_AND_BEFORE))) ON ROWS FROM [Collateral_Management]",
       "updateMode": "once"
      },
      "serverKey": "default",
      "widgetKey": "pivot-table"
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we can perform drill-down to different hierarchies in a pivot table\n",
    "session.visualize(\"explore-dataset-using-pivot-table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cube structure\n",
    "During cube creation, numeric values are automatically created as measures. Non numeric values are automatically translated to levels under hierarchy of the same name. This can be [configured](https://www.atoti.io/documentation/lib/atoti.html#atoti.session.Session.create_cube) differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = cube.measures\n",
    "h = cube.hierarchies\n",
    "lvl = cube.levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we proceed with the data aggregation aspects, let's inspect the hierarchies created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to set the hierarchy *Date* as a slicing hierarchy. A slicing hierarchy will not aggregate the data on all its members.  \n",
    "This means that we always view a subset of the cube by one date by default, which is usually what is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h[\"Date\"].slicing = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new measures  \n",
    "From the data we have, we can derive the following:   \n",
    "$Market Value = Price \\times Quantity$  \n",
    "$Collateral Value = Market Value \\times (1 - Haircut)$   \n",
    "  \n",
    "The above measures are aggregated over the Account and Asset Code levels in order to compute the Collateral Shortfall at account level:  \n",
    "$Collateral Shortfall = Collateral Value - Cash Out$   \n",
    "Where Cash Out is also aggregated at account level           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m[\"Price\"] = tt.value(assets_prices_table[\"Price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m[\"Market Value\"] = tt.agg.sum(\n",
    "    m[\"Price\"] * m[\"Quantity.SUM\"],\n",
    "    scope=tt.scope.origin(lvl[\"Sector\"], lvl[\"Country\"], lvl[\"Account\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m[\"Haircut\"] = tt.agg.sum(assets_table[\"Haircut\"])\n",
    "\n",
    "m[\"Collateral Value\"] = tt.agg.sum(\n",
    "    m[\"Price\"] * m[\"Quantity.SUM\"] * (1 - m[\"Haircut\"]),\n",
    "    scope=tt.scope.origin(lvl[\"Sector\"], lvl[\"Country\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cash_out = tt.value(loans_positions_table[\"Cash_Out\"])\n",
    "m[\"Cash Out\"] = tt.agg.sum(cash_out, scope=tt.scope.origin(lvl[\"Account\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m[\"Collateral Shortfall\"] = m[\"Collateral Value\"] - m[\"Cash Out\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore this new measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "atoti": {
     "widget": {
      "mapping": {
       "horizontalSubplots": [],
       "splitBy": [
        "ALL_MEASURES",
        "[asset_positions].[Asset_Code].[Asset_Code]"
       ],
       "values": [
        "[Measures].[Price]"
       ],
       "verticalSubplots": [],
       "xAxis": [
        "[assets_prices].[Date].[Date]"
       ]
      },
      "query": {
       "mdx": "SELECT NON EMPTY [assets_prices].[Date].[Date].Members ON ROWS, NON EMPTY Crossjoin({[Measures].[Price]}, Hierarchize(Descendants({[asset_positions].[Asset_Code].[AllMember]}, 1, SELF_AND_BEFORE))) ON COLUMNS FROM [Collateral_Management]",
       "updateMode": "once"
      },
      "serverKey": "default",
      "widgetKey": "plotly-line-chart"
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we can look at the price.VALUE across Date, further split the charts by Asset_Code\n",
    "session.visualize(\"times-series\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "atoti": {
     "widget": {
      "mapping": {
       "columns": [
        "ALL_MEASURES"
       ],
       "measures": [
        "[Measures].[Haircut]"
       ],
       "rows": [
        "[assets].[Country].[Country]",
        "[assets].[Sector].[Sector]",
        "[asset_positions].[Asset_Code].[Asset_Code]"
       ]
      },
      "query": {
       "mdx": "SELECT NON EMPTY {[Measures].[Haircut]} ON COLUMNS, NON EMPTY Crossjoin(Hierarchize(Descendants({[assets].[Country].[AllMember]}, 1, SELF_AND_BEFORE)), Hierarchize(Descendants({[assets].[Sector].[AllMember]}, 1, SELF_AND_BEFORE)), Hierarchize(Descendants({[asset_positions].[Asset_Code].[AllMember]}, 1, SELF_AND_BEFORE))) ON ROWS FROM [Collateral_Management]",
       "updateMode": "once"
      },
      "serverKey": "default",
      "widgetKey": "pivot-table"
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# give a meaningful title to the visualization. This helps to reconcile the objective of the visual and also could be the title of\n",
    "# the widget when visual is published\n",
    "session.visualize(\"haircut-value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitoring Collateral Shortfall  \n",
    "We created a pivot table for with the Collateral Shortfall, Market Value, Cash Out and Collateral Value for Accounts.  \n",
    "Negative Collateral Shortfall are highlighted in red. Feel free to click on the `>` to drill-down to other hierarchies such as Sector to account for the shortfall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "atoti": {
     "height": 282,
     "widget": {
      "mapping": {
       "columns": [
        "ALL_MEASURES"
       ],
       "measures": [
        "[Measures].[Collateral Shortfall]",
        "[Measures].[Market Value]",
        "[Measures].[Cash Out]",
        "[Measures].[Collateral Value]"
       ],
       "rows": [
        "[asset_positions].[Account].[Account]"
       ]
      },
      "query": {
       "mdx": "SELECT NON EMPTY {[Measures].[Collateral Shortfall], [Measures].[Market Value], [Measures].[Cash Out], [Measures].[Collateral Value]} ON COLUMNS, NON EMPTY Hierarchize(Descendants({[asset_positions].[Account].[AllMember]}, 1, SELF_AND_BEFORE)) ON ROWS FROM [Collateral_Management]",
       "updateMode": "once"
      },
      "serverKey": "default",
      "widgetKey": "pivot-table"
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "session.visualize(\"Collateral Shortfall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In view of all accounts, using a Gauge chart will show us that we are not yet in shortfall and how far we are from it.   \n",
    "The red marker shows the total Market value, which is the maximum threshold before shortfall will occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "atoti": {
     "widget": {
      "mapping": {
       "goal": [
        "[Measures].[Collateral Value]"
       ],
       "horizontalSubplots": [],
       "maximum": [
        "[Measures].[Market Value]"
       ],
       "minimum": [],
       "value": [
        "[Measures].[Cash Out]"
       ],
       "verticalSubplots": []
      },
      "query": {
       "mdx": "SELECT NON EMPTY {[Measures].[Cash Out], [Measures].[Market Value], [Measures].[Collateral Value]} ON COLUMNS FROM [Collateral_Management]",
       "updateMode": "once"
      },
      "serverKey": "default",
      "widgetKey": "plotly-gauge-chart"
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "session.visualize(\"total-cash-out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Cash out Bank wide  \n",
    "  \n",
    "We can use a Tree map to visualize the asset concentration. A well diversified portfolio will help to reduce the collateral risks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "atoti": {
     "widget": {
      "mapping": {
       "horizontal": [],
       "splitBy": [],
       "values": [
        "[Measures].[Market Value]"
       ],
       "vertical": [],
       "xAxis": [
        "[assets].[Sector].[Sector]",
        "[assets].[Country].[Country]"
       ]
      },
      "name": "Asset_Concentration",
      "query": {
       "mdx": "SELECT NON EMPTY Crossjoin([assets].[Sector].[Sector].Members, [assets].[Country].[Country].Members) ON ROWS, NON EMPTY [Measures].[Market Value] ON COLUMNS FROM [Collateral_Management] CELL PROPERTIES VALUE, FORMATTED_VALUE, BACK_COLOR, FORE_COLOR, FONT_FLAGS",
       "updateMode": "once"
      },
      "serverKey": "default",
      "switchedTo": "plotly-tree-map",
      "widgetKey": "plotly-line-chart"
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "session.visualize(\"Asset Concentration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## atoti UI and Dashboard creation\n",
    "Until now, we have created a few visualizations. We can right-click on the visuals to publish them as widgets.\n",
    "These widgets can then be used to build a dashboard.  \n",
    "\n",
    "<img src=\"http://data.atoti.io/notebooks/collateral-shortfall-forecast/dashboard.gif\" alt=\"collateral_dashboard\" style=\"zoom:40%;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.link(path=\"#/dashboard/3a7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click on the URL above to view the dashboard that was prepared. We can use the quick filter to select an account for viewing.  \n",
    "We can also do a right-click drillthrough to investigate the underlying data.  \n",
    "  \n",
    "To play with the UI and explore the data, [you can have a look at our UI documentation here](https://www.activeviam.com/activeui/documentation/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulations\n",
    "Now that we have basic monitoring on Collateral Shortfall, we can do some simulations in the data cube."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Price Simulation\n",
    "\n",
    "The two kinds of simulation in atoti are:\n",
    "\n",
    "- Measure simulation\n",
    "- Source simulation\n",
    "\n",
    "In Measure simulations, we modify the value of the measures in scenarios of the simulations without duplicating data.  \n",
    "Source simulation on the other hand, is a simulation created by loading a new source of modified data to the cube.\n",
    "\n",
    "Here, we will use the Source simulation to simulate variations of the price by considering the price forecast at the following different time horizons:\n",
    "\n",
    "- 1 day\n",
    "- 3 days\n",
    "- 1 week\n",
    "\n",
    "For each forecasting time horizon, we will predict the Collateral Shortfall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load the price forecast tables in a unique table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    os.path.join(\"../results/predictions\", f)\n",
    "    for f in os.listdir(\"../results/predictions\")\n",
    "    if \".csv\" in f\n",
    "]\n",
    "price_predictions_df = pd.DataFrame()\n",
    "\n",
    "for f in files:\n",
    "    price_predictions_df = pd.concat(\n",
    "        [price_predictions_df, pd.read_csv(f, index_col=0)]\n",
    "    )\n",
    "price_predictions_df = price_predictions_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_predictions_df = price_predictions_df.reset_index().rename(\n",
    "    columns={\n",
    "        \"index\": \"Date\",\n",
    "        \"y\": \"Price\",\n",
    "        \"ŷ\": \"Price Prediction\",\n",
    "        \"Asset Code\": \"Asset_Code\",\n",
    "        \"Model Name\": \"Best Model\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_predictions_df_1_day = price_predictions_df[\n",
    "    price_predictions_df[\"forecasting horizon in days\"] == 1\n",
    "][[\"Date\", \"Asset_Code\", \"Price Prediction\"]].copy()\n",
    "price_predictions_df_1_day = pd.melt(\n",
    "    price_predictions_df_1_day.sort_values([\"Asset_Code\", \"Date\"]),\n",
    "    id_vars=[\"Date\", \"Asset_Code\"],\n",
    "    value_vars=[\"Price Prediction\"],\n",
    "    value_name=\"Price\",\n",
    ")\n",
    "price_predictions_df_1_day = price_predictions_df_1_day[\n",
    "    [\"Asset_Code\", \"Date\", \"Price\"]\n",
    "].set_index([\"Asset_Code\", \"Date\"])\n",
    "price_predictions_df_1_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_predictions_df_3_days = price_predictions_df[\n",
    "    price_predictions_df[\"forecasting horizon in days\"] == 3\n",
    "][[\"Date\", \"Asset_Code\", \"Price Prediction\"]].copy()\n",
    "price_predictions_df_3_days = pd.melt(\n",
    "    price_predictions_df_3_days.sort_values([\"Asset_Code\", \"Date\"]),\n",
    "    id_vars=[\"Date\", \"Asset_Code\"],\n",
    "    value_vars=[\"Price Prediction\"],\n",
    "    value_name=\"Price\",\n",
    ")\n",
    "price_predictions_df_3_days = price_predictions_df_3_days[\n",
    "    [\"Asset_Code\", \"Date\", \"Price\"]\n",
    "].set_index([\"Asset_Code\", \"Date\"])\n",
    "price_predictions_df_3_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_predictions_df_1_week = price_predictions_df[\n",
    "    price_predictions_df[\"forecasting horizon in days\"] == 7\n",
    "][[\"Date\", \"Asset_Code\", \"Price Prediction\"]].copy()\n",
    "price_predictions_df_1_week = pd.melt(\n",
    "    price_predictions_df_1_week.sort_values([\"Asset_Code\", \"Date\"]),\n",
    "    id_vars=[\"Date\", \"Asset_Code\"],\n",
    "    value_vars=[\"Price Prediction\"],\n",
    "    value_name=\"Price\",\n",
    ")\n",
    "price_predictions_df_1_week = price_predictions_df_1_week[\n",
    "    [\"Asset_Code\", \"Date\", \"Price\"]\n",
    "].set_index([\"Asset_Code\", \"Date\"])\n",
    "price_predictions_df_1_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_prices_table.head(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the dataframes with the preictions do not have exactly the same size. This is because we consider different time horizons for the predictions.\n",
    "Indeed, when we consider different time horizons for the prediction.\n",
    "**To be able to compare the diffrent scenarios, we will filter them on the Date column and consider the period comprised from 2021/04/08 and 2022/01/24.**\n",
    "\n",
    "To achive that, we consider only the date in the following index for all the scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = price_predictions_df_1_week.index\n",
    "index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's modify the assets_prices_df that was previously loaded into the cube by modifying the price column by the values corresponding to the price forecast.\n",
    "For our *Price simulation*, we shall load this modified dataframe directly into the table as a scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Base scenario: Ground Truth Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_prices_df_base = assets_prices_df.loc[index]\n",
    "assets_prices_df = assets_prices_df_base.copy()\n",
    "assets_prices_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Source Simulation, we do not perform simulation_setup. We just load it to the table as scenarios.\n",
    "with session.start_transaction(scenario_name=\"Actual\"):\n",
    "    # assets_prices_table.scenarios[\"Actual Collateral Shortfall\"].drop()  # Clear the data from the \"base\" scenario before loading our new data\n",
    "    assets_prices_table.scenarios[\"Actual\"].load_pandas(assets_prices_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 1: Forecast At 1 Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_prices_df = price_predictions_df_1_day.loc[index].copy()\n",
    "assets_prices_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with session.start_transaction(scenario_name=\"Forecast At 1 Day\"):\n",
    "    # assets_prices_table.scenarios[\"Forecast At 1 Day\"].drop()  # Clear the data from the \"base\" scenario before loading our new data\n",
    "    assets_prices_table.scenarios[\"Forecast At 1 Day\"].load_pandas(assets_prices_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 2: Forecast At 3 Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_prices_df = price_predictions_df_3_days.loc[index].copy()\n",
    "assets_prices_df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# We define the new scenario and update the data table\n",
    "assets_prices_table.scenarios[\"Forecast At 3 Days\"].drop()\n",
    "assets_prices_table.scenarios[\"Forecast At 3 Days\"].load_pandas(assets_prices_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Source Simulation, we do not perform simulation_setup. We just load it to the table as scenarios.\n",
    "with session.start_transaction(scenario_name=\"Forecast At 3 Days\"):\n",
    "    # assets_prices_table.scenarios[\"Forecast At 3 Days\"].drop()  # Clear the data from the \"base\" scenario before loading our new data\n",
    "    assets_prices_table.scenarios[\"Forecast At 3 Days\"].load_pandas(assets_prices_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 3: Forecast At 1 Week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_prices_df = price_predictions_df_1_week.loc[index].copy()\n",
    "assets_prices_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with session.start_transaction(scenario_name=\"Forecast At 1 Week\"):\n",
    "    # assets_prices_table.scenarios[\"Forecast At 1 Week\"].drop()  # Clear the data from the \"base\" scenario before loading our new data\n",
    "    assets_prices_table.scenarios[\"Forecast At 1 Week\"].load_pandas(assets_prices_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Comparing the different scenarios\n",
    "Now, let's compare the impact on the collateral shortfall when considering different time horizon for the forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "atoti": {
     "height": 336,
     "widget": {
      "columnWidths": {
       "[Epoch].[Epoch].[Actual Collateral Shortfall],[Measures].[Collateral Shortfall]": 185,
       "[Epoch].[Epoch].[Forecast At 1 Day],[Measures].[Collateral Shortfall]": 186,
       "[Epoch].[Epoch].[Forecast At 1 Week],[Measures].[Collateral Shortfall]": 177,
       "[Epoch].[Epoch].[Forecast At 3 Days],[Measures].[Collateral Shortfall]": 176
      },
      "filters": [
       "Except([Epoch].[Epoch].Members, [Epoch].[Epoch].[Base])"
      ],
      "mapping": {
       "columns": [
        "[Epoch].[Epoch].[Branch]",
        "ALL_MEASURES"
       ],
       "measures": [
        "[Measures].[Collateral Shortfall]"
       ],
       "rows": [
        "[asset_positions].[Account].[Account]"
       ]
      },
      "query": {
       "mdx": "SELECT NON EMPTY Hierarchize(Descendants({[asset_positions].[Account].[AllMember]}, 1, SELF_AND_BEFORE)) ON ROWS, NON EMPTY Crossjoin([Epoch].[Epoch].[Branch].Members, {[Measures].[Collateral Shortfall]}) ON COLUMNS FROM [Collateral_Management] CELL PROPERTIES VALUE, FORMATTED_VALUE, BACK_COLOR, FORE_COLOR, FONT_FLAGS",
       "updateMode": "once"
      },
      "serverKey": "default",
      "widgetKey": "pivot-table"
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "session.visualize(\"Collateral Shortfall Forecasts comparison - Table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "atoti": {
     "widget": {
      "filters": [
       "Except([Epoch].[Epoch].Members, [Epoch].[Epoch].[Base])"
      ],
      "isTextVisible": true,
      "mapping": {
       "horizontalSubplots": [],
       "splitBy": [
        "ALL_MEASURES",
        "[Epoch].[Epoch].[Branch]"
       ],
       "values": [
        "[Measures].[Collateral Shortfall]"
       ],
       "verticalSubplots": [],
       "xAxis": [
        "[asset_positions].[Account].[Account]"
       ]
      },
      "query": {
       "mdx": "SELECT NON EMPTY Crossjoin({[Measures].[Collateral Shortfall]}, [Epoch].[Epoch].[Branch].Members) ON COLUMNS, NON EMPTY Hierarchize(Descendants({[asset_positions].[Account].[AllMember]}, 1, SELF_AND_BEFORE)) ON ROWS FROM [Collateral_Management]",
       "updateMode": "once"
      },
      "serverKey": "default",
      "widgetKey": "plotly-clustered-column-chart"
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "session.visualize(\"Collateral Shortfall Forecasts comparison - Plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the projections are close to the actual calculation of the Collateral Shortfall value for Daniel EK and Musk. Also, they are not far to the actual value for Buffet, Gates and Niel.\n",
    "\n",
    "However, in the case of Bezos & MacKenzie, we observe that the projections are less accurate.\n",
    "\n",
    "Additionally, in general, we note that for most of the accounts, the forecast at 1 and 3 days are close whereas the one at 1-week horizon tends to differ significantly. \n",
    "\n",
    "These observations are probably due to the fact that these portofolios do not comprised excatly the same assets, for which we have use the same model and assumptions for the forecast. Which could lead to great accuracy for some assets, and less for others. As a consequence, depending on which assets are comprised in the account, the projections could be more or less accurate in comparison the the actual Collateral Shortfall. \n",
    "\n",
    "We will explain further the performing level of the forecast later in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the dashboard that was prepared in advance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.link(path=\"#/dashboard/69e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality of the Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for asset in set(index.get_level_values(0)):\n",
    "    # Ground truth\n",
    "    y = assets_prices_df_base.loc[index].loc[asset][\"Price\"]\n",
    "\n",
    "    # Prediction at 1 day\n",
    "    y_pred_1d = price_predictions_df_1_day.loc[index].loc[asset][\"Price\"]\n",
    "    r2_1d = r2_score(y, y_pred_1d)\n",
    "    rmse_1d = mean_squared_error(y, y_pred_1d)\n",
    "    mape_1d = utils.mean_absolute_percentage_error(y, y_pred_1d)\n",
    "\n",
    "    # Prediction at 3 days\n",
    "    y_pred_3d = price_predictions_df_3_days.loc[index].loc[asset][\"Price\"]\n",
    "    r2_3d = r2_score(y, y_pred_3d)\n",
    "    rmse_3d = mean_squared_error(y, y_pred_3d)\n",
    "    mape_3d = utils.mean_absolute_percentage_error(y, y_pred_3d)\n",
    "\n",
    "    # Prediction at 1 week\n",
    "    y_pred_1w = price_predictions_df_1_week.loc[index].loc[asset][\"Price\"]\n",
    "    r2_1w = r2_score(y, y_pred_1w)\n",
    "    rmse_1w = mean_squared_error(y, y_pred_1w)\n",
    "    mape_1w = utils.mean_absolute_percentage_error(y, y_pred_1w)\n",
    "\n",
    "    # Results summary table\n",
    "    results_df = pd.DataFrame(\n",
    "        index=pd.Series(\n",
    "            [\"Prediction At 1 Day\", \"Prediction At 3 Days\", \"Prediction At 1 Week\"]\n",
    "        ),\n",
    "        columns=[\"y_mean\", \"y_std\", \"ŷ_mean\", \"ŷ_std\", \"R2\", \"RMSE\", \"MAPE\"],\n",
    "    )\n",
    "\n",
    "    metrics = {\n",
    "        \"Prediction At 1 Day\": {\n",
    "            \"y_mean\": np.mean(y),\n",
    "            \"y_std\": np.std(y),\n",
    "            \"ŷ_mean\": np.mean(y_pred_1d),\n",
    "            \"ŷ_std\": np.std(y_pred_1d),\n",
    "            \"R2\": r2_1d,\n",
    "            \"RMSE\": rmse_1d,\n",
    "            \"MAPE\": mape_1d,\n",
    "        },\n",
    "        \"Prediction At 3 Days\": {\n",
    "            \"y_mean\": np.mean(y),\n",
    "            \"y_std\": np.std(y),\n",
    "            \"ŷ_mean\": np.mean(y_pred_3d),\n",
    "            \"ŷ_std\": np.std(y_pred_3d),\n",
    "            \"R2\": r2_3d,\n",
    "            \"RMSE\": rmse_3d,\n",
    "            \"MAPE\": mape_3d,\n",
    "        },\n",
    "        \"Prediction At 1 Week\": {\n",
    "            \"y_mean\": np.mean(y),\n",
    "            \"y_std\": np.std(y),\n",
    "            \"ŷ_mean\": np.mean(y_pred_1w),\n",
    "            \"ŷ_std\": np.std(y_pred_1w),\n",
    "            \"R2\": r2_1w,\n",
    "            \"RMSE\": rmse_1w,\n",
    "            \"MAPE\": mape_1w,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    for k, v in metrics.items():\n",
    "        for m in list(v.keys()):\n",
    "            results_df.loc[k, m] = utils.truncate(v[m], 3)\n",
    "\n",
    "    print(f\"Result summary for asset code {asset}:\\n{results_df.to_markdown()}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result tables show the following predictions, and regression evaluation metrics, for each time horizon prediction:\n",
    "\n",
    "- **y_mean:** The average of the actual price of the considered asset\n",
    "- **y_std:** The standard deviation of the actual price of the considered asset\n",
    "- **ŷ_mean:** The average of the predicted price of the considered asset\n",
    "- **ŷ_std:** The average standard deviation of the predicted price of the considered asset\n",
    "- **R2:** The coefficient of determination (R squared) or regression score of the model\n",
    "- **RMSE:** The Root Mean Squared Error\n",
    "- **MAPE:** The Mean Absolute Percentage Error\n",
    "\n",
    "Refer to https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics for the definitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue' size=3>The results tables show that the forecasting models are good in general:\n",
    "\n",
    "- <font color='blue' size=3>On average, they predict values close to the actual values with associated standard deviations comparable to the actual values as well. This demonstrates a good fit of the model with a low bias, except for the asset CAP.PA;\n",
    "    \n",
    "- <font color='blue' size=3>The R2 values are also good, except for a few assets like CAP.PA, ENGI.PA and TIT.MI, they are above 0.65. This shows good correlations between the actual values and the predictions;\n",
    "    \n",
    "- <font color='blue' size=3>The RMSE are low compared to the actual prices except for the assets CAP.PA;\n",
    "    \n",
    "- <font color='blue' size=3>The MAPE values are good as they are lower than 0.05 (i.e. less than 5% deviation from the actual prices on avrage). This demonstrates that, on average, the relative error between the prediction and the actual price is less than 5%. \n",
    "    \n",
    "<font color='blue' size=3> Here, we can see the difference of performance of the models corresponding at different time horizon. **As expected with time series forecast, we observe that the closer the closer the time horizon, the better forecast.**\n",
    "    \n",
    "<font color='blue' size=3> Furthermore, we can see different performing levels at different time horizons for the same assets. But, we can also see diffrent performing levels at the same time horizon - so the same model -  for different assets. This is due to the fact that the diffrent assets do not have necessarily the haracteristics in terms of trends and seasonality, but for simplicity we have used the same assumptions to create their predictive features and forecast models. Which is not the best solution, and is definitely a way of improvment of our approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 13)\n",
    "\n",
    "colors = {\n",
    "    \"Actual Price\": \"r\",\n",
    "    \"Prediction at 1 day\": \"g\",\n",
    "    \"Prediction at 3 days\": \"b\",\n",
    "    \"Prediction at 1 week\": \"orange\",\n",
    "}\n",
    "styles = {\n",
    "    \"Actual Price\": \"--\",\n",
    "    \"Prediction at 1 day\": \"--\",\n",
    "    \"Prediction at 3 days\": \"--\",\n",
    "    \"Prediction at 1 week\": \"--\",\n",
    "}\n",
    "\n",
    "for asset in set(index.get_level_values(0)):\n",
    "    y = (\n",
    "        assets_prices_df_base.loc[index]\n",
    "        .loc[asset]\n",
    "        .reset_index()\n",
    "        .rename(columns={\"Price\": \"Actual Price\"})\n",
    "    )\n",
    "    y_pred_1d = (\n",
    "        price_predictions_df_1_day.loc[index]\n",
    "        .loc[asset]\n",
    "        .reset_index()\n",
    "        .rename(columns={\"Price\": \"Prediction at 1 day\"})\n",
    "    )\n",
    "    y_pred_3d = (\n",
    "        price_predictions_df_3_days.loc[index]\n",
    "        .loc[asset]\n",
    "        .reset_index()\n",
    "        .rename(columns={\"Price\": \"Prediction at 3 days\"})\n",
    "    )\n",
    "    y_pred_1w = (\n",
    "        price_predictions_df_1_week.loc[index]\n",
    "        .loc[asset]\n",
    "        .reset_index()\n",
    "        .rename(columns={\"Price\": \"Prediction at 1 week\"})\n",
    "    )\n",
    "\n",
    "    # df = pd.merge(left=y, right=y_pred_1d, on='Date')\n",
    "    df = y.merge(\n",
    "        y_pred_1d.merge(\n",
    "            y_pred_3d.merge(y_pred_1w, how=\"inner\", on=\"Date\"), how=\"inner\", on=\"Date\"\n",
    "        ),\n",
    "        how=\"inner\",\n",
    "        on=\"Date\",\n",
    "    )\n",
    "    df = df.set_index(\"Date\")\n",
    "\n",
    "    df.plot(\n",
    "        color=[colors.get(x) for x in df.columns],\n",
    "        style=[styles.get(x) for x in df.columns],\n",
    "    )\n",
    "    plt.title(f\"Actual Price vs Predictions for asset code {asset}\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue' size=3>The visualizations confirm the previous observations, as well as the good fit of the different models in general:\n",
    "\n",
    "- <font color='blue' size=3>In general, the curves of predicted prices correspond well to those of actual prices, in terms of amplitude and trend;\n",
    "    \n",
    "- <font color='blue' size=3>The forecast at 1 day appears to be the best globally;\n",
    "    \n",
    "- <font color='blue' size=3>Although the 1-week forecast seems to be less good than the other models, its curves seem to be quite good since they follow the trend of real prices well in most cases, with however some relatively large deviations in amplitude for the different assets except BNP.PA, RACE.MI, TIT.MI, and ENGI.PA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "<font size=3>In this analysis, we have analyzed the risk of Collateral Shortfall for some portfolios in projection in a near future at different time horizons.\n",
    "\n",
    "<font size=3>While the different time horizons used show an overall good forecast accuray, we observe that the models' performance decrease when we increase the forecast horizon: in general, the closer the forecast horizon, the better the forecast values.\n",
    "\n",
    "<font size=3>We show how machine learning can be very effective in helping portfolio managers make informed decisions and manage risk taking into account different considerations such as the time/accuracy trade-off. In fact, machine learning can help assess the best strategy for the firm between a longer-term view with relatively low accuracy, and a shorter-term view with more accurate projections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\" ><a href=\"https://www.atoti.io/?utm_source=gallery&utm_content=collateral-monitoring\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://data.atoti.io/notebooks/banners/discover-try.png\" alt=\"Try atoti\"></a></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
