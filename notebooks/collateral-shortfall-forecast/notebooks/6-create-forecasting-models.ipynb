{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d34e8d53",
   "metadata": {},
   "source": [
    "# Forecasting of Asset Valueslassification of the Fire Using OPLS-DA\n",
    "\n",
    "#### In this notebook, we use machine learning to forecast the values of assests.\n",
    "#### To achieve this, we use the Orthogonal Partial Least Square Discriminant Analysis (OPLS-DA) technique.\n",
    "\n",
    "#### We consider 3 different time horizons to forecast:\n",
    "\n",
    "#### **- 1-day horizon**\n",
    "#### **- 3-days horizon**\n",
    "#### **- 7-days horizon**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fceac3",
   "metadata": {},
   "source": [
    "### Import some packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3266aaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import lightgbm as lgbm\n",
    "from sklearn.model_selection import cross_val_predict, LeaveOneOut\n",
    "from sklearn.metrics import (\n",
    "    r2_score,\n",
    "    explained_variance_score,\n",
    "    mean_squared_error,\n",
    "    mean_absolute_percentage_error,\n",
    ")\n",
    "\n",
    "from pyopls import OPLS\n",
    "from pyopls import OPLSValidator, OPLSDAValidator\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf16ee9",
   "metadata": {},
   "source": [
    "### Global variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dbf8ea6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RESULTS = \"../results\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05cfe0c-c8e0-48d1-be7e-571a598145e0",
   "metadata": {},
   "source": [
    "### Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f12c09f-3779-44fe-b7ac-40c60cf1955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate(num, digits):\n",
    "\n",
    "    truncated_num = num\n",
    "\n",
    "    try:\n",
    "        sp = str(num).split(\".\")\n",
    "        int_part = sp[0]\n",
    "        dec_part = sp[1]\n",
    "\n",
    "        if digits > len(dec_part):\n",
    "            digits = len(dec_part)\n",
    "        truncated_num = float(\".\".join([int_part, dec_part[:digits]]))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return truncated_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49cfac9b-9ae6-4f4a-9906-0ee03d026190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_summary():\n",
    "    \"\"\"\n",
    "    Build the result tables that summarize the performance of the model.\n",
    "    The tables contain the results of the forecast of all the assets at different time horizons.\n",
    "    Different\n",
    "\n",
    "    Return:\n",
    "        The tables containing all the results of forecast.\n",
    "    \"\"\"\n",
    "\n",
    "    assets = [\n",
    "        \"AC.PA\",\n",
    "        \"BNP.PA\",\n",
    "        \"CAP.PA\",\n",
    "        \"ENGI.PA\",\n",
    "        \"G.MI\",\n",
    "        \"RACE.MI\",\n",
    "        \"SAN.PA\",\n",
    "        \"TIT.MI\",\n",
    "    ]\n",
    "    horizons = [\"1-day-horizon--\", \"3-days-horizon--\", \"7-days-horizon--\"]\n",
    "\n",
    "    values = len(assets) * len(horizons)\n",
    "\n",
    "    with tqdm(total=values, file=sys.stdout) as pbar:\n",
    "        for horizon in horizons:\n",
    "            # initialize the lists of all the predictions\n",
    "            y = []\n",
    "            ŷ_pls = []\n",
    "            ŷ_opls = []\n",
    "            ŷ_xgboost = []\n",
    "            ŷ_aug_xgboost = []\n",
    "\n",
    "            for asset in assets:\n",
    "                train = pd.read_csv(\n",
    "                    os.path.join(\n",
    "                        RESULTS,\n",
    "                        \"features\",\n",
    "                        \"features-\" + horizon + asset + \"-train.csv\",\n",
    "                    ),\n",
    "                    index_col=0,\n",
    "                )\n",
    "                test = pd.read_csv(\n",
    "                    os.path.join(\n",
    "                        RESULTS, \"features\", \"features-\" + horizon + asset + \"-test.csv\"\n",
    "                    ),\n",
    "                    index_col=0,\n",
    "                )\n",
    "\n",
    "                X_cols = [c for c in train.columns if c != \"target\"]\n",
    "                y_col = \"target\"\n",
    "\n",
    "                X_train = train[X_cols]\n",
    "                y_train = train[y_col]\n",
    "\n",
    "                X_test = test[X_cols]\n",
    "                y_test = test[y_col]\n",
    "\n",
    "                # PLS\n",
    "                pls_model = PLSRegression(1).fit(X_train, y_train)\n",
    "\n",
    "                # OPLS model\n",
    "                ncomp = 20\n",
    "                opls = OPLS(ncomp)\n",
    "                Z_train = opls.fit_transform(X_train, y_train)\n",
    "                opls_model = PLSRegression(1).fit(Z_train, y_train)\n",
    "\n",
    "                # XGBoost models\n",
    "                xgboost_params = {\n",
    "                    \"max_features\": \"auto\",\n",
    "                    \"n_estimators\": 10000,\n",
    "                    \"n_iter_no_change\": 5,\n",
    "                    \"random_state\": 42,\n",
    "                }\n",
    "                xgboost_model = GradientBoostingRegressor(**xgboost_params).fit(\n",
    "                    X_train, y_train\n",
    "                )\n",
    "                augmented_xgboost_model = GradientBoostingRegressor(\n",
    "                    **xgboost_params\n",
    "                ).fit(Z_train, y_train)\n",
    "\n",
    "                # Make predictions on the test\n",
    "                # and compute some evaluation values\n",
    "                n = len(X_test)  # sample size\n",
    "                p = 1  # number of independant variables (=number of PLS component)\n",
    "\n",
    "                y_pred_test_pls = pls_model.predict(X_test)\n",
    "                r2_test_pls = r2_score(y_test, y_pred_test_pls)\n",
    "                r2_adj_test_pls = 1 - (1 - r2_test_pls) * (n - 1) / (n - p - 1)\n",
    "                rmse_test_pls = mean_squared_error(y_test, y_pred_test_pls)\n",
    "                mape_test_pls = mean_absolute_percentage_error(y_test, y_pred_test_pls)\n",
    "\n",
    "                Z_test = opls.transform(X_test)\n",
    "                y_pred_test_opls = opls_model.predict(Z_test)\n",
    "                r2_test_opls = r2_score(y_test, y_pred_test_opls)\n",
    "                r2_adj_test_opls = 1 - (1 - r2_test_opls) * (n - 1) / (n - p - 1)\n",
    "                rmse_test_opls = mean_squared_error(y_test, y_pred_test_opls)\n",
    "                mape_test_opls = mean_absolute_percentage_error(\n",
    "                    y_test, y_pred_test_opls\n",
    "                )\n",
    "\n",
    "                y_pred_test_xgboost = xgboost_model.predict(X_test)\n",
    "                r2_test_xgboost = r2_score(y_test, y_pred_test_xgboost)\n",
    "                r2_adj_test_xgboost = xgboost_model.score(\n",
    "                    X_test, y_test\n",
    "                )  # 1-(1-r2_test_xgboost)*(n-1)/(n-p-1)\n",
    "                rmse_test_xgboost = mean_squared_error(y_test, y_pred_test_xgboost)\n",
    "                mape_test_xgboost = mean_absolute_percentage_error(\n",
    "                    y_test, y_pred_test_xgboost\n",
    "                )\n",
    "\n",
    "                y_pred_test_aug_xgboost = augmented_xgboost_model.predict(Z_test)\n",
    "                r2_test_aug_xgboost = r2_score(y_test, y_pred_test_aug_xgboost)\n",
    "                r2_adj_test_aug_xgboost = augmented_xgboost_model.score(\n",
    "                    Z_test, y_test\n",
    "                )  # 1-(1-r2_test_aug_xgboost)*(n-1)/(n-p-1)\n",
    "                rmse_test_aug_xgboost = mean_squared_error(\n",
    "                    y_test, y_pred_test_aug_xgboost\n",
    "                )\n",
    "                mape_test_aug_xgboost = mean_absolute_percentage_error(\n",
    "                    y_test, y_pred_test_aug_xgboost\n",
    "                )\n",
    "\n",
    "                # Create the results table\n",
    "\n",
    "                # Table with the predictions\n",
    "                values_test = {\n",
    "                    \"Ground Truth\": y_test,\n",
    "                    \"PLS Prediction\": y_pred_test_pls,\n",
    "                    \"O-PLS Prediction\": y_pred_test_opls,\n",
    "                    \"XGBoost Prediction\": y_pred_test_xgboost,\n",
    "                    \"Augmented XGBoost Prediction\": y_pred_test_aug_xgboost,\n",
    "                }\n",
    "\n",
    "                results_test = pd.DataFrame(columns=list(values_test.keys()))\n",
    "\n",
    "                for k, v in values_test.items():\n",
    "                    results_test[k] = truncate(v, 3)\n",
    "                results_test[\"forecasting_horizon_in_days\"] = [\n",
    "                    int(horizon.split(\"-\")[0])\n",
    "                ] * len(results_test)\n",
    "                results_test[\"asset_code\"] = [asset] * len(results_test)\n",
    "\n",
    "                # Results summary table\n",
    "                summary_table = pd.DataFrame(\n",
    "                    index=pd.Series([\"PLS\", \"O-PLS\", \"XGBoost\", \"Augmented XGBoost\"]),\n",
    "                    columns=[\n",
    "                        \"R2\",\n",
    "                        \"RMSE\",\n",
    "                        \"MAPE\",\n",
    "                        \"y_mean\",\n",
    "                        \"y_std\",\n",
    "                        \"ŷ_mean\",\n",
    "                        \"ŷ_std\",\n",
    "                    ],\n",
    "                )\n",
    "\n",
    "                values = {\n",
    "                    \"PLS\": {\n",
    "                        \"R2\": r2_test_pls,\n",
    "                        \"RMSE\": rmse_test_pls,\n",
    "                        \"MAPE\": mape_test_pls,\n",
    "                        \"y_mean\": np.mean(y_test),\n",
    "                        \"y_std\": np.std(y_test),\n",
    "                        \"ŷ_mean\": np.mean(y_pred_test_pls),\n",
    "                        \"ŷ_std\": np.std(y_pred_test_pls),\n",
    "                    },\n",
    "                    \"O-PLS\": {\n",
    "                        \"R2\": r2_test_opls,\n",
    "                        \"RMSE\": rmse_test_opls,\n",
    "                        \"MAPE\": mape_test_opls,\n",
    "                        \"y_mean\": np.mean(y_test),\n",
    "                        \"y_std\": np.std(y_test),\n",
    "                        \"ŷ_mean\": np.mean(y_pred_test_opls),\n",
    "                        \"ŷ_std\": np.std(y_pred_test_opls),\n",
    "                    },\n",
    "                    \"XGBoost\": {\n",
    "                        \"R2\": r2_test_xgboost,\n",
    "                        \"RMSE\": rmse_test_xgboost,\n",
    "                        \"MAPE\": mape_test_xgboost,\n",
    "                        \"y_mean\": np.mean(y_test),\n",
    "                        \"y_std\": np.std(y_test),\n",
    "                        \"ŷ_mean\": np.mean(y_pred_test_xgboost),\n",
    "                        \"ŷ_std\": np.std(y_pred_test_xgboost),\n",
    "                    },\n",
    "                    \"Augmented XGBoost\": {\n",
    "                        \"R2\": r2_test_aug_xgboost,\n",
    "                        \"RMSE\": rmse_test_aug_xgboost,\n",
    "                        \"MAPE\": mape_test_aug_xgboost,\n",
    "                        \"y_mean\": np.mean(y_test),\n",
    "                        \"y_std\": np.std(y_test),\n",
    "                        \"ŷ_mean\": np.mean(y_pred_test_aug_xgboost),\n",
    "                        \"ŷ_std\": np.std(y_pred_test_aug_xgboost),\n",
    "                    },\n",
    "                }\n",
    "                for k, v in values.items():\n",
    "                    for m in list(v.keys()):\n",
    "                        summary_table.loc[k, m] = truncate(v[m], 3)\n",
    "                summary_table[\"asset_code\"] = [asset] * len(summary_table)\n",
    "\n",
    "                # append the predictions to the overall lists\n",
    "                y.append(y_test)\n",
    "                ŷ_pls.append(y_pred_test_pls)\n",
    "                ŷ_opls.append(y_pred_test_opls)\n",
    "                ŷ_xgboost.append(y_pred_test_xgboost)\n",
    "                ŷ_aug_xgboost.append(y_pred_test_aug_xgboost)\n",
    "\n",
    "                # save the tables\n",
    "                results_test.to_csv(\n",
    "                    os.path.join(\n",
    "                        RESULTS,\n",
    "                        \"predictions\",\n",
    "                        \"predictions-\" + horizon + asset + \"-test.csv\",\n",
    "                    )\n",
    "                )\n",
    "                summary_table.to_csv(\n",
    "                    os.path.join(\n",
    "                        RESULTS, \"summary\", \"summary-\" + horizon + asset + \"-test.csv\"\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                res = \"predictions-\" + horizon + asset + \"-test.csv\"\n",
    "                pbar.write(f\"processed: {res}\")\n",
    "                pbar.update(1)\n",
    "                sleep(1)\n",
    "\n",
    "            # flatten lists of predictions\n",
    "            y = [p for el in y for p in el]\n",
    "            ŷ_pls = [p for el in ŷ_pls for p in el]\n",
    "            ŷ_opls = [p for el in ŷ_opls for p in el]\n",
    "            ŷ_xgboost = [p for el in ŷ_xgboost for p in el]\n",
    "            ŷ_aug_xgboost = [p for el in ŷ_aug_xgboost for p in el]\n",
    "\n",
    "            # compute the overall metrics\n",
    "            n = len(y)  # sample size\n",
    "            p = 1  # number of independant variables (=number of PLS component)\n",
    "            r2_pls = r2_score(y, ŷ_pls)\n",
    "            r2_adj_pls = 1 - (1 - r2_pls) * (n - 1) / (n - p - 1)\n",
    "            rmse_pls = mean_squared_error(y, ŷ_pls)\n",
    "            mape_pls = mean_absolute_percentage_error(y, ŷ_pls)\n",
    "\n",
    "            r2_opls = r2_score(y, ŷ_opls)\n",
    "            r2_adj_opls = 1 - (1 - r2_opls) * (n - 1) / (n - p - 1)\n",
    "            rmse_opls = mean_squared_error(y, ŷ_opls)\n",
    "            mape_opls = mean_absolute_percentage_error(y, ŷ_opls)\n",
    "\n",
    "            r2_xgboost = r2_score(y, ŷ_xgboost)\n",
    "            r2_adj_xgboost = 1 - (1 - r2_xgboost) * (n - 1) / (n - p - 1)\n",
    "            rmse_xgboost = mean_squared_error(y, ŷ_xgboost)\n",
    "            mape_xgboost = mean_absolute_percentage_error(y, ŷ_xgboost)\n",
    "\n",
    "            r2_aug_xgboost = r2_score(y, ŷ_aug_xgboost)\n",
    "            r2_adj_aug_xgboost = 1 - (1 - r2_aug_xgboost) * (n - 1) / (n - p - 1)\n",
    "            rmse_aug_xgboost = mean_squared_error(y, ŷ_aug_xgboost)\n",
    "            mape_aug_xgboost = mean_absolute_percentage_error(y, ŷ_aug_xgboost)\n",
    "\n",
    "            # create the overall summary results table\n",
    "            summary = pd.DataFrame(\n",
    "                index=pd.Series([\"PLS\", \"O-PLS\", \"XGBoost\", \"Augmented XGBoost\"]),\n",
    "                columns=[\"R2\", \"RMSE\", \"MAPE\", \"y_mean\", \"y_std\", \"ŷ_mean\", \"ŷ_std\"],\n",
    "            )\n",
    "\n",
    "            values = {\n",
    "                \"PLS\": {\n",
    "                    \"R2\": truncate(np.mean(r2_pls), 3),\n",
    "                    \"RMSE\": truncate(np.mean(rmse_pls), 3),\n",
    "                    \"MAPE\": truncate(mape_pls, 3),\n",
    "                    \"y_mean\": np.mean(y),\n",
    "                    \"y_std\": np.std(y),\n",
    "                    \"ŷ_mean\": np.mean(ŷ_pls),\n",
    "                    \"ŷ_std\": np.std(ŷ_pls),\n",
    "                },\n",
    "                \"O-PLS\": {\n",
    "                    \"R2\": truncate(np.mean(r2_opls), 3),\n",
    "                    \"RMSE\": truncate(np.mean(rmse_opls), 3),\n",
    "                    \"MAPE\": truncate(mape_opls, 3),\n",
    "                    \"y_mean\": np.mean(y),\n",
    "                    \"y_std\": np.std(y),\n",
    "                    \"ŷ_mean\": np.mean(ŷ_opls),\n",
    "                    \"ŷ_std\": np.std(ŷ_opls),\n",
    "                },\n",
    "                \"XGBoost\": {\n",
    "                    \"R2\": truncate(np.mean(r2_xgboost), 3),\n",
    "                    \"RMSE\": truncate(np.mean(rmse_xgboost), 3),\n",
    "                    \"MAPE\": truncate(mape_xgboost, 3),\n",
    "                    \"y_mean\": np.mean(y),\n",
    "                    \"y_std\": np.std(y),\n",
    "                    \"ŷ_mean\": np.mean(ŷ_xgboost),\n",
    "                    \"ŷ_std\": np.std(ŷ_xgboost),\n",
    "                },\n",
    "                \"Augmented XGBoost\": {\n",
    "                    \"R2\": truncate(np.mean(r2_aug_xgboost), 3),\n",
    "                    \"RMSE\": truncate(np.mean(rmse_aug_xgboost), 3),\n",
    "                    \"MAPE\": truncate(mape_aug_xgboost, 3),\n",
    "                    \"y_mean\": np.mean(y),\n",
    "                    \"y_std\": np.std(y),\n",
    "                    \"ŷ_mean\": np.mean(ŷ_aug_xgboost),\n",
    "                    \"ŷ_std\": np.std(ŷ_aug_xgboost),\n",
    "                },\n",
    "            }\n",
    "            for k, v in values.items():\n",
    "                for m in list(v.keys()):\n",
    "                    summary.loc[k, m] = truncate(v[m], 3)\n",
    "\n",
    "            # save overall summary table\n",
    "            summary.to_csv(\n",
    "                os.path.join(\n",
    "                    RESULTS, \"summary\", \"summary-\" + horizon + \"-all-assets-test.csv\"\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ba3ddd-0ca3-4b3b-8ecb-9701038c6054",
   "metadata": {},
   "source": [
    "# Build and export the result tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8758bd1b-5d66-4c5b-8886-c9abc4bb1def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed: predictions-1-day-horizon--AC.PA-test.csv                                                                                                   \n",
      "processed: predictions-1-day-horizon--BNP.PA-test.csv                                                                                                  \n",
      "processed: predictions-1-day-horizon--CAP.PA-test.csv                                                                                                  \n",
      "processed: predictions-1-day-horizon--ENGI.PA-test.csv                                                                                                 \n",
      "processed: predictions-1-day-horizon--G.MI-test.csv                                                                                                    \n",
      "processed: predictions-1-day-horizon--RACE.MI-test.csv                                                                                                 \n",
      "processed: predictions-1-day-horizon--SAN.PA-test.csv                                                                                                  \n",
      "processed: predictions-1-day-horizon--TIT.MI-test.csv                                                                                                  \n",
      "processed: predictions-3-days-horizon--AC.PA-test.csv                                                                                                  \n",
      "processed: predictions-3-days-horizon--BNP.PA-test.csv                                                                                                 \n",
      "processed: predictions-3-days-horizon--CAP.PA-test.csv                                                                                                 \n",
      "processed: predictions-3-days-horizon--ENGI.PA-test.csv                                                                                                \n",
      "processed: predictions-3-days-horizon--G.MI-test.csv                                                                                                   \n",
      "processed: predictions-3-days-horizon--RACE.MI-test.csv                                                                                                \n",
      "processed: predictions-3-days-horizon--SAN.PA-test.csv                                                                                                 \n",
      "processed: predictions-3-days-horizon--TIT.MI-test.csv                                                                                                 \n",
      "processed: predictions-7-days-horizon--AC.PA-test.csv                                                                                                  \n",
      "processed: predictions-7-days-horizon--BNP.PA-test.csv                                                                                                 \n",
      "processed: predictions-7-days-horizon--CAP.PA-test.csv                                                                                                 \n",
      "processed: predictions-7-days-horizon--ENGI.PA-test.csv                                                                                                \n",
      "processed: predictions-7-days-horizon--G.MI-test.csv                                                                                                   \n",
      "processed: predictions-7-days-horizon--RACE.MI-test.csv                                                                                                \n",
      "processed: predictions-7-days-horizon--SAN.PA-test.csv                                                                                                 \n",
      "processed: predictions-7-days-horizon--TIT.MI-test.csv                                                                                                 \n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [02:48<00:00,  7.00s/it]\n",
      "CPU times: user 2min 48s, sys: 1min 38s, total: 4min 26s\n",
      "Wall time: 2min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "build_model_summary()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.r5.24xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
