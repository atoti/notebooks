{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d34e8d53",
   "metadata": {},
   "source": [
    "# Forecasting of Asset Valueslassification of the Fire Using OPLS-DA\n",
    "\n",
    "#### In this notebook, we use machine learning to forecast the values of assests.\n",
    "#### To achieve this, we use the Orthogonal Partial Least Square Discriminant Analysis (OPLS-DA) technique.\n",
    "\n",
    "#### We consider 3 different time horizons to forecast:\n",
    "\n",
    "#### **- 1-day horizon**\n",
    "#### **- 3-days horizon**\n",
    "#### **- 7-days horizon**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fceac3",
   "metadata": {},
   "source": [
    "### Import some packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3266aaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import lightgbm as lgbm\n",
    "from sklearn.model_selection import cross_val_predict, LeaveOneOut\n",
    "from sklearn.metrics import r2_score, explained_variance_score, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "from pyopls import OPLS\n",
    "from pyopls import OPLSValidator, OPLSDAValidator\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf16ee9",
   "metadata": {},
   "source": [
    "### Global variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dbf8ea6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RESULTS = '../results'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05cfe0c-c8e0-48d1-be7e-571a598145e0",
   "metadata": {},
   "source": [
    "### Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f12c09f-3779-44fe-b7ac-40c60cf1955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate(num, digits):\n",
    "    \n",
    "    truncated_num = num\n",
    "    \n",
    "    try:\n",
    "        sp = str(num).split('.')\n",
    "        int_part = sp[0]\n",
    "        dec_part = sp[1]\n",
    "        \n",
    "        if digits > len(dec_part):\n",
    "            digits = len(dec_part)\n",
    "        truncated_num = float('.'.join([int_part, dec_part[:digits]]))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return truncated_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49cfac9b-9ae6-4f4a-9906-0ee03d026190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_summary():\n",
    "    \"\"\"\n",
    "    Build the result tables that summarize the performance of the model.\n",
    "    The tables contain the results of the forecast of all the assets at different time horizons.\n",
    "    Different \n",
    "    \n",
    "    Return:\n",
    "        The tables containing all the results of forecast.\n",
    "    \"\"\"\n",
    "    \n",
    "    assets = ['AC.PA', 'BNP.PA', 'CAP.PA', 'ENGI.PA', 'G.MI', 'RACE.MI', 'SAN.PA', 'TIT.MI']\n",
    "    horizons = ['1-day-horizon--', '3-days-horizon--', '7-days-horizon--']\n",
    "    \n",
    "    values = len(assets) * len(horizons)\n",
    "            \n",
    "    with tqdm(total=values, file=sys.stdout) as pbar:\n",
    "        for horizon in horizons:\n",
    "            # initialize the lists of all the predictions\n",
    "            y = []\n",
    "            ŷ_pls = [] \n",
    "            ŷ_opls = []\n",
    "            ŷ_xgboost = []\n",
    "            ŷ_aug_xgboost = []\n",
    "            \n",
    "            for asset in assets:\n",
    "                train = pd.read_csv(os.path.join(RESULTS, 'features', 'features-' + horizon + asset + '-train.csv'), index_col=0)\n",
    "                test = pd.read_csv(os.path.join(RESULTS, 'features', 'features-' + horizon + asset + '-test.csv'), index_col=0)\n",
    "                \n",
    "                X_cols = [c for c in train.columns if c!='target']\n",
    "                y_col = 'target'\n",
    "                \n",
    "                X_train = train[X_cols]\n",
    "                y_train = train[y_col]\n",
    "                \n",
    "                X_test = test[X_cols]\n",
    "                y_test = test[y_col]\n",
    "                \n",
    "                # PLS\n",
    "                pls_model = PLSRegression(1).fit(X_train, y_train)\n",
    "                \n",
    "                #OPLS model\n",
    "                ncomp = 20\n",
    "                opls = OPLS(ncomp)\n",
    "                Z_train = opls.fit_transform(X_train, y_train)\n",
    "                opls_model = PLSRegression(1).fit(Z_train, y_train)\n",
    "                \n",
    "                # XGBoost models\n",
    "                xgboost_params = {\n",
    "                    'max_features': 'auto',\n",
    "                    'n_estimators': 10000,\n",
    "                    'n_iter_no_change': 5,\n",
    "                    'random_state': 42\n",
    "                }\n",
    "                xgboost_model = GradientBoostingRegressor(**xgboost_params).fit(X_train, y_train)\n",
    "                augmented_xgboost_model = GradientBoostingRegressor(**xgboost_params).fit(Z_train, y_train)\n",
    "                \n",
    "                \n",
    "                # Make predictions on the test\n",
    "                # and compute some evaluation values\n",
    "                n = len(X_test) # sample size\n",
    "                p = 1 # number of independant variables (=number of PLS component)\n",
    "                \n",
    "                y_pred_test_pls = pls_model.predict(X_test)\n",
    "                r2_test_pls = r2_score(y_test, y_pred_test_pls)\n",
    "                r2_adj_test_pls = 1-(1-r2_test_pls)*(n-1)/(n-p-1)\n",
    "                rmse_test_pls = mean_squared_error(y_test, y_pred_test_pls)\n",
    "                mape_test_pls = mean_absolute_percentage_error(y_test, y_pred_test_pls)\n",
    "                \n",
    "                Z_test = opls.transform(X_test)\n",
    "                y_pred_test_opls = opls_model.predict(Z_test)\n",
    "                r2_test_opls = r2_score(y_test, y_pred_test_opls)\n",
    "                r2_adj_test_opls = 1-(1-r2_test_opls)*(n-1)/(n-p-1)\n",
    "                rmse_test_opls = mean_squared_error(y_test, y_pred_test_opls)\n",
    "                mape_test_opls = mean_absolute_percentage_error(y_test, y_pred_test_opls)\n",
    "                \n",
    "                y_pred_test_xgboost = xgboost_model.predict(X_test)\n",
    "                r2_test_xgboost = r2_score(y_test, y_pred_test_xgboost)\n",
    "                r2_adj_test_xgboost = xgboost_model.score(X_test, y_test) # 1-(1-r2_test_xgboost)*(n-1)/(n-p-1)\n",
    "                rmse_test_xgboost = mean_squared_error(y_test, y_pred_test_xgboost)\n",
    "                mape_test_xgboost  = mean_absolute_percentage_error(y_test, y_pred_test_xgboost)\n",
    "                \n",
    "                y_pred_test_aug_xgboost = augmented_xgboost_model.predict(Z_test)\n",
    "                r2_test_aug_xgboost = r2_score(y_test, y_pred_test_aug_xgboost)\n",
    "                r2_adj_test_aug_xgboost = augmented_xgboost_model.score(Z_test, y_test) # 1-(1-r2_test_aug_xgboost)*(n-1)/(n-p-1)\n",
    "                rmse_test_aug_xgboost = mean_squared_error(y_test, y_pred_test_aug_xgboost)\n",
    "                mape_test_aug_xgboost  = mean_absolute_percentage_error(y_test, y_pred_test_aug_xgboost)\n",
    "                \n",
    "                # Create the results table\n",
    "                \n",
    "                # Table with the predictions\n",
    "                values_test = {'Ground Truth': y_test, \n",
    "                               'PLS Prediction': y_pred_test_pls, \n",
    "                               'O-PLS Prediction': y_pred_test_opls, \n",
    "                               'XGBoost Prediction': y_pred_test_xgboost, \n",
    "                               'Augmented XGBoost Prediction': y_pred_test_aug_xgboost}\n",
    "    \n",
    "                results_test = pd.DataFrame(columns=list(values_test.keys()))\n",
    "                \n",
    "                for k, v in values_test.items():\n",
    "                    results_test[k] = truncate(v, 3)\n",
    "                results_test['forecasting_horizon_in_days'] = [int(horizon.split('-')[0])] * len(results_test)\n",
    "                results_test['asset_code'] = [asset] * len(results_test)\n",
    "                \n",
    "                # Results summary table\n",
    "                summary_table = pd.DataFrame(index=pd.Series(['PLS', 'O-PLS', 'XGBoost', 'Augmented XGBoost']), \n",
    "                                             columns=['R2', 'RMSE', 'MAPE', 'y_mean', 'y_std', 'ŷ_mean', 'ŷ_std'])\n",
    "                \n",
    "                values = {\n",
    "                    'PLS': {'R2': r2_test_pls, 'RMSE': rmse_test_pls, 'MAPE': mape_test_pls, 'y_mean': np.mean(y_test), 'y_std': np.std(y_test), \n",
    "                            'ŷ_mean': np.mean(y_pred_test_pls), 'ŷ_std': np.std(y_pred_test_pls)}, \n",
    "                    'O-PLS': {'R2': r2_test_opls, 'RMSE': rmse_test_opls, 'MAPE': mape_test_opls, 'y_mean': np.mean(y_test), 'y_std': np.std(y_test), \n",
    "                              'ŷ_mean': np.mean(y_pred_test_opls), 'ŷ_std': np.std(y_pred_test_opls)}, \n",
    "                    'XGBoost': {'R2': r2_test_xgboost, 'RMSE': rmse_test_xgboost, 'MAPE': mape_test_xgboost, 'y_mean': np.mean(y_test), 'y_std': np.std(y_test), \n",
    "                                'ŷ_mean': np.mean(y_pred_test_xgboost), 'ŷ_std': np.std(y_pred_test_xgboost)}, \n",
    "                    'Augmented XGBoost': {'R2': r2_test_aug_xgboost, 'RMSE': rmse_test_aug_xgboost, 'MAPE': mape_test_aug_xgboost, 'y_mean': np.mean(y_test), \n",
    "                                          'y_std': np.std(y_test), 'ŷ_mean': np.mean(y_pred_test_aug_xgboost), 'ŷ_std': np.std(y_pred_test_aug_xgboost)}\n",
    "                }\n",
    "                for k, v in values.items():\n",
    "                    for m in list(v.keys()):\n",
    "                        summary_table.loc[k, m] = truncate(v[m], 3)\n",
    "                summary_table['asset_code'] = [asset] * len(summary_table)\n",
    "                \n",
    "                # append the predictions to the overall lists\n",
    "                y.append(y_test)\n",
    "                ŷ_pls.append(y_pred_test_pls) \n",
    "                ŷ_opls.append(y_pred_test_opls)\n",
    "                ŷ_xgboost.append(y_pred_test_xgboost)\n",
    "                ŷ_aug_xgboost.append(y_pred_test_aug_xgboost)\n",
    "                        \n",
    "                # save the tables\n",
    "                results_test.to_csv(os.path.join(RESULTS, 'predictions', 'predictions-' + horizon + asset + '-test.csv'))\n",
    "                summary_table.to_csv(os.path.join(RESULTS, 'summary', 'summary-' + horizon + asset + '-test.csv'))\n",
    "                \n",
    "                res = 'predictions-' + horizon + asset + '-test.csv'\n",
    "                pbar.write(f'processed: {res}')\n",
    "                pbar.update(1)\n",
    "                sleep(1)\n",
    "            \n",
    "            # flatten lists of predictions\n",
    "            y = [p for el in y for p in el]\n",
    "            ŷ_pls = [p for el in ŷ_pls for p in el]\n",
    "            ŷ_opls = [p for el in ŷ_opls for p in el]\n",
    "            ŷ_xgboost = [p for el in ŷ_xgboost for p in el]\n",
    "            ŷ_aug_xgboost = [p for el in ŷ_aug_xgboost for p in el]\n",
    "            \n",
    "            # compute the overall metrics\n",
    "            n = len(y) # sample size\n",
    "            p = 1 # number of independant variables (=number of PLS component)\n",
    "            r2_pls = r2_score(y, ŷ_pls)\n",
    "            r2_adj_pls = 1-(1-r2_pls)*(n-1)/(n-p-1)\n",
    "            rmse_pls = mean_squared_error(y, ŷ_pls)\n",
    "            mape_pls = mean_absolute_percentage_error(y, ŷ_pls)\n",
    "            \n",
    "            r2_opls = r2_score(y, ŷ_opls)\n",
    "            r2_adj_opls = 1-(1-r2_opls)*(n-1)/(n-p-1)\n",
    "            rmse_opls = mean_squared_error(y, ŷ_opls)\n",
    "            mape_opls = mean_absolute_percentage_error(y, ŷ_opls)\n",
    "            \n",
    "            r2_xgboost = r2_score(y, ŷ_xgboost)\n",
    "            r2_adj_xgboost = 1-(1-r2_xgboost)*(n-1)/(n-p-1)\n",
    "            rmse_xgboost = mean_squared_error(y, ŷ_xgboost)\n",
    "            mape_xgboost = mean_absolute_percentage_error(y, ŷ_xgboost)\n",
    "            \n",
    "            r2_aug_xgboost = r2_score(y, ŷ_aug_xgboost)\n",
    "            r2_adj_aug_xgboost = 1-(1-r2_aug_xgboost)*(n-1)/(n-p-1)\n",
    "            rmse_aug_xgboost = mean_squared_error(y, ŷ_aug_xgboost)\n",
    "            mape_aug_xgboost = mean_absolute_percentage_error(y, ŷ_aug_xgboost)\n",
    "            \n",
    "            # create the overall summary results table\n",
    "            summary = pd.DataFrame(index=pd.Series(['PLS', 'O-PLS', 'XGBoost', 'Augmented XGBoost']), columns=['R2', 'RMSE', 'MAPE', 'y_mean', 'y_std', 'ŷ_mean', 'ŷ_std'])\n",
    "            \n",
    "            values = {\n",
    "                'PLS': {'R2': truncate(np.mean(r2_pls), 3), 'RMSE': truncate(np.mean(rmse_pls), 3), 'MAPE': truncate(mape_pls, 3), 'y_mean': np.mean(y), \n",
    "                        'y_std': np.std(y), 'ŷ_mean': np.mean(ŷ_pls), 'ŷ_std': np.std(ŷ_pls)}, \n",
    "                'O-PLS': {'R2': truncate(np.mean(r2_opls), 3), 'RMSE': truncate(np.mean(rmse_opls), 3), 'MAPE': truncate(mape_opls, 3), 'y_mean': np.mean(y), \n",
    "                          'y_std': np.std(y), 'ŷ_mean': np.mean(ŷ_opls), 'ŷ_std': np.std(ŷ_opls)}, \n",
    "                'XGBoost': {'R2': truncate(np.mean(r2_xgboost), 3), 'RMSE': truncate(np.mean(rmse_xgboost), 3), 'MAPE': truncate(mape_xgboost, 3), 'y_mean': np.mean(y), \n",
    "                            'y_std': np.std(y), 'ŷ_mean': np.mean(ŷ_xgboost), 'ŷ_std': np.std(ŷ_xgboost)}, \n",
    "                'Augmented XGBoost': {'R2': truncate(np.mean(r2_aug_xgboost), 3), 'RMSE': truncate(np.mean(rmse_aug_xgboost), 3), 'MAPE': truncate(mape_aug_xgboost, 3), \n",
    "                                      'y_mean': np.mean(y), 'y_std': np.std(y), 'ŷ_mean': np.mean(ŷ_aug_xgboost), 'ŷ_std': np.std(ŷ_aug_xgboost)}\n",
    "                }\n",
    "            for k, v in values.items():\n",
    "                for m in list(v.keys()):\n",
    "                    summary.loc[k, m] = truncate(v[m], 3)\n",
    "                        \n",
    "            # save overall summary table\n",
    "            summary.to_csv(os.path.join(RESULTS, 'summary', 'summary-' + horizon + '-all-assets-test.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ba3ddd-0ca3-4b3b-8ecb-9701038c6054",
   "metadata": {},
   "source": [
    "# Build and export the result tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8758bd1b-5d66-4c5b-8886-c9abc4bb1def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed: predictions-1-day-horizon--AC.PA-test.csv                                                                                                   \n",
      "processed: predictions-1-day-horizon--BNP.PA-test.csv                                                                                                  \n",
      "processed: predictions-1-day-horizon--CAP.PA-test.csv                                                                                                  \n",
      "processed: predictions-1-day-horizon--ENGI.PA-test.csv                                                                                                 \n",
      "processed: predictions-1-day-horizon--G.MI-test.csv                                                                                                    \n",
      "processed: predictions-1-day-horizon--RACE.MI-test.csv                                                                                                 \n",
      "processed: predictions-1-day-horizon--SAN.PA-test.csv                                                                                                  \n",
      "processed: predictions-1-day-horizon--TIT.MI-test.csv                                                                                                  \n",
      "processed: predictions-3-days-horizon--AC.PA-test.csv                                                                                                  \n",
      "processed: predictions-3-days-horizon--BNP.PA-test.csv                                                                                                 \n",
      "processed: predictions-3-days-horizon--CAP.PA-test.csv                                                                                                 \n",
      "processed: predictions-3-days-horizon--ENGI.PA-test.csv                                                                                                \n",
      "processed: predictions-3-days-horizon--G.MI-test.csv                                                                                                   \n",
      "processed: predictions-3-days-horizon--RACE.MI-test.csv                                                                                                \n",
      "processed: predictions-3-days-horizon--SAN.PA-test.csv                                                                                                 \n",
      "processed: predictions-3-days-horizon--TIT.MI-test.csv                                                                                                 \n",
      "processed: predictions-7-days-horizon--AC.PA-test.csv                                                                                                  \n",
      "processed: predictions-7-days-horizon--BNP.PA-test.csv                                                                                                 \n",
      "processed: predictions-7-days-horizon--CAP.PA-test.csv                                                                                                 \n",
      "processed: predictions-7-days-horizon--ENGI.PA-test.csv                                                                                                \n",
      "processed: predictions-7-days-horizon--G.MI-test.csv                                                                                                   \n",
      "processed: predictions-7-days-horizon--RACE.MI-test.csv                                                                                                \n",
      "processed: predictions-7-days-horizon--SAN.PA-test.csv                                                                                                 \n",
      "processed: predictions-7-days-horizon--TIT.MI-test.csv                                                                                                 \n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [02:48<00:00,  7.00s/it]\n",
      "CPU times: user 2min 48s, sys: 1min 38s, total: 4min 26s\n",
      "Wall time: 2min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "build_model_summary()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.r5.24xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
