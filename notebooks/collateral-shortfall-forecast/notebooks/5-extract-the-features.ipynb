{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0967f56e-2ddd-4653-bb91-1aa35827e40e",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "\n",
    "### In this notebook, we perform feature extraction from our dataset using the tsfresh package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d337120a",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e66c624a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os, re\n",
    "import pandas as pd, numpy as np\n",
    "import random\n",
    "from natsort import natsorted\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from tsfresh import extract_features, select_features, extract_relevant_features\n",
    "from tsfresh.utilities.dataframe_functions import impute, make_forecasting_frame, roll_time_series\n",
    "from tsfresh.feature_extraction import ComprehensiveFCParameters, EfficientFCParameters, MinimalFCParameters, settings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29af439c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available cpus: 16\n",
      "\n",
      "Number of cpus to use: 14\n"
     ]
    }
   ],
   "source": [
    "num_cpus = multiprocessing.cpu_count() - 2\n",
    "\n",
    "print(f'Number of available cpus: {multiprocessing.cpu_count()}\\n')\n",
    "print(f'Number of cpus to use: {num_cpus}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257358c9",
   "metadata": {},
   "source": [
    "### Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b8dca39",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLLED_DATAFRAMES_PATH = '../results/rolled-dataset'\n",
    "FEATURES_DATAFRAMES_PATH = '../results/features'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ca9b47-afc3-462e-a316-115136185d17",
   "metadata": {},
   "source": [
    "### Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c614e45-e73e-4c7d-97b8-6c9dd9752a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features_dataframes(input_path, output_path):\n",
    "    # list all the rolled dataset\n",
    "    rolled_datasets_train = natsorted([d for d in os.listdir(input_path) if 'train' in d])\n",
    "    rolled_datasets_test = natsorted([d for d in os.listdir(input_path) if 'test' in d])\n",
    "    sanity_check = True\n",
    "    error_tracker = []\n",
    "    \n",
    "    # loop over the rolled datasets\n",
    "    # to extract the features\n",
    "    \n",
    "    print('Starting features extraction...\\n\\n')\n",
    "    for i in range(len(rolled_datasets_train)):\n",
    "        \n",
    "        # load the data\n",
    "        train = rolled_datasets_train[i]\n",
    "        test = rolled_datasets_test[i]\n",
    "        \n",
    "        with open(os.path.join(input_path, train), \"rb\") as fIn:\n",
    "            stored_data = pickle.load(fIn)\n",
    "            X_train = stored_data['X']\n",
    "            y_train = stored_data['y']\n",
    "            \n",
    "        with open(os.path.join(input_path, test), \"rb\") as fIn:\n",
    "            stored_data = pickle.load(fIn)\n",
    "            X_test = stored_data['X']\n",
    "            y_test = stored_data['y']\n",
    "            \n",
    "        # extract the dates\n",
    "        ids_train = list(np.unique(X_train.id))\n",
    "        dates_train = []\n",
    "        \n",
    "        for idx in ids_train:\n",
    "            temp = X_train[X_train['id']==idx].reset_index(drop=True)\n",
    "            dates_train.append(temp.iloc[len(temp)-1, 3])\n",
    "        dates_train = pd.DataFrame(dates_train, columns=['date'])\n",
    "                \n",
    "        ids_test = list(np.unique(X_test.id))\n",
    "        dates_test = []\n",
    "        \n",
    "        for idx in ids_test:\n",
    "            temp = X_test[X_test['id']==idx].reset_index(drop=True)\n",
    "            dates_test.append(temp.iloc[len(temp)-1, 3])\n",
    "        dates_test = pd.DataFrame(dates_test, columns=['date'])\n",
    "                    \n",
    "        # extract the features\n",
    "        cols = ['id', 'time', 'asset_value']\n",
    "        features_train = extract_features(X_train[cols],\n",
    "                                          default_fc_parameters=ComprehensiveFCParameters(), # we could use also: MinimalFCParameters(), EfficientFCParameters() \n",
    "                                          column_id='id',\n",
    "                                          column_sort='time',\n",
    "                                          impute_function=impute,\n",
    "                                          n_jobs=num_cpus)\n",
    "        \n",
    "        features_test = extract_features(X_test[cols],\n",
    "                                          default_fc_parameters=ComprehensiveFCParameters(), # we could use also: MinimalFCParameters(), EfficientFCParameters() \n",
    "                                          column_id='id',\n",
    "                                          column_sort='time',\n",
    "                                          impute_function=impute,\n",
    "                                          n_jobs=num_cpus)\n",
    "        \n",
    "        # remove the rows whose target values are NaNs\n",
    "        remove_indices_train = y_train['target'].index[y_train['target'].apply(np.isnan)]\n",
    "        indices_train = [idx for idx in y_train.index if idx not in remove_indices_train]\n",
    "        \n",
    "        remove_indices_test = y_test['target'].index[y_test['target'].apply(np.isnan)]\n",
    "        indices_test = [idx for idx in y_test.index if idx not in remove_indices_test]\n",
    "        \n",
    "        features_train = features_train.reset_index(drop=True)\n",
    "        features_train = features_train.iloc[indices_train]\n",
    "        y_train = y_train.iloc[indices_train]\n",
    "        dates_train = dates_train.iloc[indices_train]\n",
    "        \n",
    "        features_test = features_test.reset_index(drop=True)\n",
    "        features_test = features_test.iloc[indices_test]\n",
    "        y_test = y_test.iloc[indices_test]\n",
    "        dates_test = dates_test.iloc[indices_test]\n",
    "        \n",
    "        # normalize the features\n",
    "        cols = features_train.columns\n",
    "        scaler = StandardScaler()\n",
    "        features_train = pd.DataFrame(scaler.fit_transform(features_train), columns=cols)\n",
    "        features_test = pd.DataFrame(scaler.transform(features_test), columns=cols)\n",
    "        \n",
    "        # add the dates\n",
    "        features_train['day'] = pd.to_datetime(dates_train['date']).dt.day\n",
    "        features_train['week'] = pd.to_datetime(dates_train['date']).dt.week\n",
    "        features_train['month'] = pd.to_datetime(dates_train['date']).dt.month\n",
    "        \n",
    "        features_test['day'] = pd.to_datetime(dates_test['date']).dt.day\n",
    "        features_test['week'] = pd.to_datetime(dates_test['date']).dt.week\n",
    "        features_test['month'] = pd.to_datetime(dates_test['date']).dt.month\n",
    "        \n",
    "        # filter the features\n",
    "        features_selected_train = select_features(features_train, y_train.target)\n",
    "        features_selected_test = features_test[features_selected_train.columns]\n",
    "        \n",
    "        # generate the final dataframe\n",
    "        # containing the filtered features and the target\n",
    "        df_train = features_selected_train.merge(y_train.target, left_index=True, right_index=True)\n",
    "        df_test = features_selected_test.merge(y_test.target, left_index=True, right_index=True)\n",
    "        \n",
    "        # add dates index\n",
    "        index_train = pd.Series(list(dates_train['date']))\n",
    "        df_train = df_train.set_index(index_train)\n",
    "        \n",
    "        index_test = pd.Series(list(dates_test['date']))\n",
    "        df_test = df_test.set_index(index_test)\n",
    "        \n",
    "        # export to csv and pickle\n",
    "        filename_train = re.sub('.pkl', '.csv', re.sub('rolled-dataset', 'features', train))\n",
    "        filename_test = re.sub('.pkl', '.csv', re.sub('rolled-dataset', 'features', test))\n",
    "        filename_scaler = re.sub('-train', '', re.sub('rolled-dataset', 'scaler', train))\n",
    "        \n",
    "        df_train.to_csv(os.path.join(output_path, filename_train))\n",
    "        df_test.to_csv(os.path.join(output_path, filename_test))\n",
    "        with open(os.path.join(output_path, filename_scaler), \"wb\") as fOut:\n",
    "            pickle.dump(scaler, fOut, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "        # sanity check\n",
    "        check = np.unique(df_test.columns == df_train.columns)\n",
    "        if len(check) > 1 or not check[0]:\n",
    "            sanity_check = False\n",
    "            error_tracker.append((filename_test, filename_train))\n",
    "            \n",
    "    if sanity_check:\n",
    "        print('\\n\\n...Features extraction completed, all the files are OK!!!\\n\\n')\n",
    "    else:\n",
    "        print('\\n\\n...The following pairs of files are not matching:')\n",
    "        for el in error_tracker:\n",
    "            print(el)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e51b30-bc40-4f76-946a-d86eb3899eed",
   "metadata": {},
   "source": [
    "# STEP 1: Generate Features Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d34b9153-24aa-47b4-971e-b2a066a4af9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting features extraction...\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [00:05<00:00, 11.28it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 38.43it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [00:06<00:00, 10.87it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 37.16it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [00:05<00:00, 11.29it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 39.48it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [00:06<00:00, 10.54it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 35.40it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [00:06<00:00, 10.08it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 37.75it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [00:06<00:00, 10.12it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 37.27it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [00:06<00:00,  9.98it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 35.97it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [00:06<00:00,  9.62it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 34.24it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [00:07<00:00,  9.00it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 31.33it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [00:06<00:00,  9.66it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 37.38it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [00:06<00:00, 10.43it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 37.60it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [00:06<00:00, 10.21it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 35.97it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [00:06<00:00, 10.12it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 38.07it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [00:06<00:00,  9.68it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 34.61it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [00:06<00:00, 10.12it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 36.25it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [00:07<00:00,  9.28it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 35.33it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [00:06<00:00,  9.88it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 34.69it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [00:06<00:00,  9.60it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 35.41it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [00:06<00:00, 10.21it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 40.16it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [00:06<00:00, 10.22it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 36.91it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [00:06<00:00,  9.95it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 38.37it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [00:06<00:00,  9.98it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 35.49it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [00:07<00:00,  9.53it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 37.76it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [00:07<00:00,  9.32it/s]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 34.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "...Features extraction completed, all the files are OK!!!\n",
      "\n",
      "\n",
      "CPU times: user 2min 29s, sys: 12.4 s, total: 2min 41s\n",
      "Wall time: 5min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "generate_features_dataframes(ROLLED_DATAFRAMES_PATH, FEATURES_DATAFRAMES_PATH)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.r5.24xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
