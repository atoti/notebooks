{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aca1c50b",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "\n",
    "### In this notebook, we perform feature extraction from our dataset using the tsfresh package.\n",
    "\n",
    "#### We consider a binary classification problem with the following classes:\n",
    "\n",
    "#### - Class -1: Non-critical fire (burns less than 10 000 acres)\n",
    "#### - Class 1: Critical fire (burns more than 10 000 acres)\n",
    "\n",
    "#### Also, we consider the scenario where we want to predict if the fire is going to grow critically within the next 6 hours.\n",
    "\n",
    "#### This horizon of prediction of 6 hours is arbitrary (you could change it), and corresponds to the delay that could be to mobilise the appropriate resources to deal with the fire before it becomes critical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfe866f",
   "metadata": {},
   "source": [
    "### Install some required packages\n",
    "#### Only install those that are not installed yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadcaf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install natsort\n",
    "!pip install tsfresh\n",
    "!pip install -U pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4960fc",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ae211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import pandas as pd, numpy as np\n",
    "import random\n",
    "from natsort import natsorted\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import datetime\n",
    "from datetime import date, timedelta\n",
    "import time\n",
    "\n",
    "from tsfresh import extract_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import (\n",
    "    impute,\n",
    "    make_forecasting_frame,\n",
    "    roll_time_series,\n",
    ")\n",
    "from tsfresh.feature_extraction import (\n",
    "    ComprehensiveFCParameters,\n",
    "    EfficientFCParameters,\n",
    "    MinimalFCParameters,\n",
    "    settings,\n",
    ")\n",
    "\n",
    "import ast\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9549da6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cpus = multiprocessing.cpu_count()\n",
    "\n",
    "print(f\"Number of available cpus: {multiprocessing.cpu_count()}\\n\")\n",
    "print(f\"Number of cpus to use: {num_cpus}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc233ca",
   "metadata": {},
   "source": [
    "### Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5532b618",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS = \"../results\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd21a8f",
   "metadata": {},
   "source": [
    "### Utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dd8f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sorter(l):\n",
    "    \"\"\"\n",
    "    Create a dict from the list to map to 0..len(l)\n",
    "    Returns a mapper to map a series to this custom sort order\n",
    "    \"\"\"\n",
    "    sort_order = {k: v for k, v in zip(l, range(len(l)))}\n",
    "    return lambda s: s.map(lambda x: sort_order[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d98c8a7",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963e6fa2",
   "metadata": {},
   "source": [
    "### Rolled dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61ecc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rolled_train = pd.read_csv(\n",
    "    os.path.join(RESULTS, \"fires-stations-final-dataset-flat-format-rolled-train.csv\")\n",
    ")\n",
    "df_rolled_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c950359",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rolled_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d78b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols = [\n",
    "    \"id\",\n",
    "    \"time_step\",\n",
    "    \"ghi_station_1\",\n",
    "    \"dni_station_1\",\n",
    "    \"wind_speed_station_1\",\n",
    "    \"wind_direction_station_1\",\n",
    "    \"dhi_station_1\",\n",
    "    \"air_temperature_station_1\",\n",
    "    \"solar_zenith_angle_station_1\",\n",
    "    \"ghi_station_2\",\n",
    "    \"dni_station_2\",\n",
    "    \"wind_speed_station_2\",\n",
    "    \"wind_direction_station_2\",\n",
    "    \"dhi_station_2\",\n",
    "    \"air_temperature_station_2\",\n",
    "    \"solar_zenith_angle_station_2\",\n",
    "    \"duration_in_hours\",\n",
    "]\n",
    "\n",
    "y_col = [\"category\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277cb8b0-7e79-4f72-a432-50cb21092bf4",
   "metadata": {},
   "source": [
    "#### Running this cell could take a very long time\n",
    "#### This could last until a few hours\n",
    "#### Please consider using distributed calculation, e.g. with Dask or PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0d28fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train = extract_features(\n",
    "    df_rolled_train[X_cols],\n",
    "    column_id=\"id\",\n",
    "    column_sort=\"time_step\",\n",
    "    default_fc_parameters=ComprehensiveFCParameters(),  # we could use also: MinimalFCParameters(), EfficientFCParameters()\n",
    "    impute_function=impute,\n",
    "    n_jobs=num_cpus,\n",
    ")\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103c19ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a068d5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(\n",
    "    os.path.join(\n",
    "        RESULTS,\n",
    "        \"extracted-features-ComprehensiveFCParameters-full--without-target-horizon-6h-train.csv\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fb95f0",
   "metadata": {},
   "source": [
    "# STEP 1: Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f154b25",
   "metadata": {},
   "source": [
    "### Hypothesis:\n",
    "### Here, we want to predict the evolution of the considered in the near future, given the parameters provided by the surrounding stations the last couple of hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a232309",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\n",
    "    os.path.join(\n",
    "        RESULTS,\n",
    "        \"extracted-features-ComprehensiveFCParameters-full--without-target-horizon-6h-train.csv\",\n",
    "    ),\n",
    "    index_col=0,\n",
    ")\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af78f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd4a659",
   "metadata": {},
   "source": [
    "### Set the horizons of prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93efb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon_6h = 6\n",
    "# horizon_12h = 12\n",
    "# horizon_18h = 18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cd97da",
   "metadata": {},
   "source": [
    "### Create the target vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76373f1c",
   "metadata": {},
   "source": [
    "#### Scenario 1: Horizon of prediction of 6 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a3e80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rolled_train[\"id\"] = df_rolled_train[\"id\"].apply(\n",
    "    lambda idx: idx if not isinstance(idx, str) else ast.literal_eval(idx)\n",
    ")\n",
    "train_ids = list(np.unique(df_rolled_train[\"id\"]))\n",
    "X_train_6h = X_train.copy()\n",
    "X_train_6h = X_train_6h.reset_index()\n",
    "X_train_6h.rename(columns={X_train_6h.columns[0]: \"id\"}, inplace=True)\n",
    "X_train_6h[\"id\"] = X_train_6h[\"id\"].apply(\n",
    "    lambda idx: idx if not isinstance(idx, str) else ast.literal_eval(idx)\n",
    ")\n",
    "X_train_6h = X_train_6h.sort_values(\"id\", key=make_sorter(train_ids))\n",
    "X_train_6h = X_train_6h.set_index(\"id\")\n",
    "X_train_6h = X_train_6h.rename_axis(index=None)\n",
    "# remove the last id\n",
    "# as we cannot find any label to assign to it\n",
    "X_train_6h = X_train_6h[:-horizon_6h]\n",
    "\n",
    "train_target_dic_6h = {}\n",
    "\n",
    "# loop over all the ids\n",
    "# excepted the last\n",
    "for idx in range(len(train_ids) - horizon_6h):\n",
    "    temp_df_6h = df_rolled_train[\n",
    "        df_rolled_train[\"id\"] == train_ids[idx + horizon_6h]\n",
    "    ].reset_index(drop=True)\n",
    "    train_target_dic_6h[train_ids[idx]] = temp_df_6h.loc[\n",
    "        len(temp_df_6h) - 1, \"category\"\n",
    "    ]\n",
    "\n",
    "train_target_6h = [\n",
    "    train_target_dic_6h[idx]\n",
    "    if not isinstance(idx, str)\n",
    "    else train_target_dic_6h[ast.literal_eval(idx)]\n",
    "    for idx in X_train_6h.index\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01ef276",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_6h = X_train_6h.copy()\n",
    "train_df_6h[\"target\"] = train_target_6h\n",
    "train_df_6h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d0aed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_6h.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca9018e",
   "metadata": {},
   "source": [
    "### Save the full dataset of extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da11028a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_6h.to_csv(\n",
    "    os.path.join(\n",
    "        RESULTS,\n",
    "        \"extracted-features-ComprehensiveFCParameters-full-target-horizon-6h-train.csv\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94960da",
   "metadata": {},
   "source": [
    "### Filter the descriptor columns\n",
    "### We use the ***select_features*** function of tsfresh to retain only the most relevant descriptors of the X dataframe w.r.t the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb23423",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_6h = train_df_6h[\"target\"]\n",
    "train_target_6h.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef65ee69-3f4b-4324-8be6-67aa8cf4e866",
   "metadata": {},
   "source": [
    "#### Running this cell could take many minutes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bed0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train_filtered_6h = select_features(X_train_6h, train_target_6h)\n",
    "X_train_filtered_6h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58f315e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_filtered_6h = X_train_filtered_6h.copy()\n",
    "train_df_filtered_6h[\"target\"] = train_target_6h\n",
    "train_df_filtered_6h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d74028",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_filtered_6h.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7212fd8",
   "metadata": {},
   "source": [
    "### Save the filtered dataset of extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b257c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_filtered_6h.to_csv(\n",
    "    os.path.join(\n",
    "        RESULTS,\n",
    "        \"extracted-features-ComprehensiveFCParameters-filtered-target-horizon-6h-train.csv\",\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
