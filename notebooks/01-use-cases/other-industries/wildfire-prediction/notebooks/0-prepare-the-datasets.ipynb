{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "258f6799",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "### In this notebook, we transform the data into the required format for our latter prediction analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b8cc8a",
   "metadata": {},
   "source": [
    "### Install some required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0683e30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install s3fs\n",
    "!pip install natsort\n",
    "!pip install geopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470df207",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f62b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd, numpy as np\n",
    "import random\n",
    "from scipy import stats\n",
    "from natsort import natsorted\n",
    "from collections import Counter\n",
    "\n",
    "import datetime\n",
    "from datetime import date, timedelta\n",
    "import time\n",
    "\n",
    "from geopy.distance import geodesic\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef39923",
   "metadata": {},
   "source": [
    "### Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6306715",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS = \"../results\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3226ae",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41848c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_distance(a, b, unit=\"km\"):\n",
    "    \"\"\"\n",
    "    Calculates the geodesic distance between the two points a and b using the geodesic distance.\n",
    "\n",
    "    Arguments:\n",
    "        a: a point defined by its latitude and longitude (lat_a, lon_a)\n",
    "        b: a point defined by its latitude and longitude (lat_b, lon_b)\n",
    "        unit: the desired unit of the the calculated distance (defaault: km)\n",
    "\n",
    "    return: the geodesic distance between a and b in the desired unit.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if unit == \"km\":\n",
    "            return geodesic(a, b).km\n",
    "        elif unit == \"miles\":\n",
    "            return geodesic(a, b).miles\n",
    "        elif unit == \"m\":\n",
    "            return geodesic(a, b).m\n",
    "    except:\n",
    "        raise ValueError(\n",
    "            \"Points must be defined as tuple or list: (latitude, longitude) or [latitude, longitude]!\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3162d11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retain_stations_per_fire(\n",
    "    fires_names,\n",
    "    stations_names,\n",
    "    fires_stations_distances,\n",
    "    proximity=10.0,\n",
    "    num_stations_retained=2,\n",
    "):\n",
    "    \"\"\"\n",
    "    Gives the list of stations to be considered for each fire.\n",
    "\n",
    "    Arguments:\n",
    "        fires_names: list of the fires names\n",
    "        stations_names: list of the stations names\n",
    "        fires_stations_distances: array containing the distances between the fires and the stations (in km)\n",
    "        proximity: the maximum distance a station must be from a fire to be considered (in km)\n",
    "\n",
    "    return: the dictionary containing the fires with their lists of stations to be considered.\n",
    "    \"\"\"\n",
    "\n",
    "    # instantiate an empty dictionary\n",
    "    fire_stations = {}\n",
    "\n",
    "    # loop over the fires\n",
    "    for idx in range(len(fires_stations_distances)):\n",
    "        # get the ids of the stations far from less than 10 kms\n",
    "        stations_ids = np.nonzero(fires_stations_distances[idx] <= proximity)[0]\n",
    "\n",
    "        # if there there are some \"close\" stations (10 kms around)\n",
    "        if len(stations_ids) >= num_stations_retained:\n",
    "            # sort the stations ids by ascending distance from the considered fire\n",
    "            pos = np.argsort(fires_stations_distances[idx][stations_ids])\n",
    "            stations_ids = stations_ids[pos][:num_stations_retained]\n",
    "            # get the fire and associated stations names\n",
    "            fire = fires_names[idx]\n",
    "            stations = [stations_names[i] for i in stations_ids]\n",
    "            # finally, append the fire and its associated stations to the dictionary\n",
    "            fire_stations[fire] = stations\n",
    "\n",
    "    return fire_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa522981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_station_data_from_fire_dates(fire, station):\n",
    "    \"\"\"\n",
    "    Get the data of the given station for the period when the given fire happened.\n",
    "\n",
    "    Arguments:\n",
    "        fire: the name of the fire to be considered\n",
    "        station: the name of the station to be considered\n",
    "\n",
    "    Return:\n",
    "        A filtered dataframe containing the station data.\n",
    "    \"\"\"\n",
    "\n",
    "    df_fires = fire_data[fire_data[\"Fire\"] == fire].copy()\n",
    "    # df_fires['StartedDate'] = pd.to_datetime(df_fires['StartedDate'], unit=\"ns\", utc=True)\n",
    "    # df_fires['EndedDate'] = pd.to_datetime(df_fires['EndedDate'], unit=\"ns\", utc=True)\n",
    "    df_fires[\"EndedDate\"] = df_fires[\"EndedDate\"].apply(\n",
    "        lambda x: x + datetime.timedelta(days=1)\n",
    "    )\n",
    "    try:\n",
    "        df_fires[\"EndedDate\"] = df_fires[\"EndedDate\"].dt.tz_localize(\"UTC\")\n",
    "    except:\n",
    "        df_fires[\"EndedDate\"] = df_fires[\"EndedDate\"].dt.tz_convert(\"UTC\")\n",
    "\n",
    "    start_date, end_date = df_fires.iloc[0, 2], df_fires.iloc[0, 3]\n",
    "    start_year, end_year = start_date.year, end_date.year\n",
    "    start_month, end_month = start_date.month, end_date.month\n",
    "    start_day, end_day = start_date.day, end_date.day\n",
    "    years = list(set([start_year, end_year]))\n",
    "\n",
    "    stations_dic = {\n",
    "        \"2016\": data_2016,\n",
    "        \"2017\": data_2017,\n",
    "        \"2018\": data_2018,\n",
    "        \"2019\": data_2019,\n",
    "        \"2020\": data_2020,\n",
    "        \"2021\": data_2020,\n",
    "    }\n",
    "\n",
    "    df_station = None\n",
    "\n",
    "    # select the fire had started and ended the same year\n",
    "    if len(years) < 2:\n",
    "        df_station_start = stations_dic[str(start_year)].copy()\n",
    "        df_station = df_station_start[df_station_start[\"Station\"] == station]\n",
    "\n",
    "    else:\n",
    "        df_station_end = stations_dic[str(end_year)].copy()\n",
    "        df_station = pd.concat(\n",
    "            [df_station, df_station_end[df_station_end[\"Station\"] == station]]\n",
    "        )\n",
    "\n",
    "    # filter the data on the periode when the fire had happened\n",
    "    # we consider that the fire had not started before 12PM (we consider only natural cause, so when the fire starts because of the heat)\n",
    "    df_station[\"datetime\"] = df_station[\"datetime\"].apply(pd.to_datetime)\n",
    "    df_station = df_station[\n",
    "        (df_station[\"datetime\"].dt.date >= start_date)\n",
    "        & (df_station[\"datetime\"].dt.date <= end_date)\n",
    "    ]\n",
    "    df_station = df_station.sort_values(\"datetime\").reset_index(drop=True)\n",
    "    df_station = df_station.iloc[12:].reset_index(drop=True)\n",
    "\n",
    "    return df_station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5740327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_fire_crticity(dataframe, fire_info, acres_burnt_threshold=10000):\n",
    "    \"\"\"\n",
    "    Add the number of acres burnt by the fires, and their associated criticity (fire category) with regard to the considered threshold:\n",
    "\n",
    "        - Fires that burn more than the considered threshold of acres burnt are considered critical (class 1)\n",
    "        - Fires that burn less than the considered threshold of acres burnt are considered non-critical (class -1)\n",
    "\n",
    "    Arguments:\n",
    "        dataframe: dataframe with the information of the fires and their associated stations\n",
    "        fire_info: dictionary containing the number of acres burnt and the category of each fire\n",
    "        acres_burnt_threshold: the considered threshold of acres burnt\n",
    "\n",
    "    Return:\n",
    "        The dataframe updated with the information of the number of acres burnt and the associated category of the fire at this moment, for each row.\n",
    "    \"\"\"\n",
    "\n",
    "    def multiply_values(a, b):\n",
    "        return a * b\n",
    "\n",
    "    cols = list(dataframe.columns) + [\"acres_burnt\", \"category\"]\n",
    "    df = pd.DataFrame()\n",
    "    fires = natsorted(list(set(dataframe[\"fire\"])))\n",
    "\n",
    "    for fire in fires:\n",
    "        temp_df = (\n",
    "            dataframe[dataframe[\"fire\"] == fire]\n",
    "            .drop_duplicates(subset=[\"fire\", \"station\", \"datetime\"])\n",
    "            .sort_values(\"datetime\")\n",
    "        )\n",
    "        # wind speeds registererd during the same period\n",
    "        # we normalize them by dividing by the mean\n",
    "        wind_speed = [\n",
    "            np.mean([speed_station_1, speed_station_2]) / temp_df[\"wind_speed\"].mean()\n",
    "            for speed_station_1, speed_station_2 in zip(\n",
    "                list(temp_df[temp_df[\"station\"] == \"station_1\"][\"wind_speed\"]),\n",
    "                list(temp_df[temp_df[\"station\"] == \"station_2\"][\"wind_speed\"]),\n",
    "            )\n",
    "        ]\n",
    "        wind_speed = wind_speed[1:]\n",
    "\n",
    "        # total surface burnt\n",
    "        acres_burnt = fire_info[fire][\"acres_burnt\"]\n",
    "        # average surface burnt\n",
    "        # we consider the half of the lenght of the reduced dataset because there are two stations\n",
    "        # and we remove the first values as it corresponds to the begining of the fire\n",
    "        mean_acres_burnt_per_hour = acres_burnt / (\n",
    "            len(temp_df[temp_df[\"station\"] == \"station_1\"]) - 1\n",
    "        )\n",
    "        # approximate surface burnt per hour\n",
    "        # we multily the average surface burnt by the weighted wind speed per each row\n",
    "        acres_burnt_per_hour = [mean_acres_burnt_per_hour] * (\n",
    "            len(temp_df[temp_df[\"station\"] == \"station_1\"]) - 1\n",
    "        )\n",
    "        acres_burnt_per_hour = [\n",
    "            acres_burnt_per_hour[idx] * wind_speed[idx]\n",
    "            for idx in range(len(acres_burnt_per_hour))\n",
    "        ]\n",
    "        acres_burnt_per_hour = np.cumsum(acres_burnt_per_hour)\n",
    "\n",
    "        for station in [\"station_1\", \"station_2\"]:\n",
    "            # we drop the first row at it corresponds to the begining of the fire (time step 0)\n",
    "            temp_df_station = temp_df[temp_df[\"station\"] == station][1:].reset_index(\n",
    "                drop=True\n",
    "            )\n",
    "\n",
    "            # add the number of acres burnt per hour to the existing dataframe\n",
    "            temp_df_station[\"acres_burnt\"] = acres_burnt_per_hour\n",
    "            # add the criticity of the fire at each time step\n",
    "            temp_df_station[\"category\"] = temp_df_station[\"acres_burnt\"].apply(\n",
    "                lambda x: \"-1\" if x < acres_burnt_threshold else \"1\"\n",
    "            )\n",
    "            # append to the final output\n",
    "            df = pd.concat([df, temp_df_station[cols]])\n",
    "\n",
    "    # format the final output\n",
    "    df = df[cols].sort_values([\"fire\", \"station\", \"datetime\"]).reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aeb772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_fire_duration(dataframe):\n",
    "    \"\"\"\n",
    "    Add the elapse time since the begin of the fire until the current time step for each row.\n",
    "\n",
    "    Arguments:\n",
    "        dataframe: dataframe with the information of the fires and their associated stations\n",
    "\n",
    "    Return:\n",
    "        The dataframe updated with the information of the elapse time since the beginin of the fire.\n",
    "    \"\"\"\n",
    "\n",
    "    cols = [c for c in dataframe.columns if c != \"category\"] + [\n",
    "        \"duration_in_hours\",\n",
    "        \"category\",\n",
    "    ]\n",
    "    df = pd.DataFrame()\n",
    "    fires = natsorted(list(set(dataframe[\"fire\"])))\n",
    "\n",
    "    for fire in fires:\n",
    "        for station in [\"station_1\", \"station_2\"]:\n",
    "            temp_df = (\n",
    "                dataframe[\n",
    "                    (dataframe[\"fire\"] == fire) & (dataframe[\"station\"] == station)\n",
    "                ]\n",
    "                .drop_duplicates(subset=[\"fire\", \"station\", \"datetime\"])\n",
    "                .sort_values(\"datetime\")\n",
    "            )\n",
    "            temp_df[\"duration_in_hours\"] = np.arange(1, len(temp_df) + 1)\n",
    "            df = pd.concat([df, temp_df[cols].reset_index(drop=True)])\n",
    "\n",
    "    df = df[cols].sort_values([\"fire\", \"station\", \"datetime\"]).reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db24e68e",
   "metadata": {},
   "source": [
    "# Load and explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3dd263",
   "metadata": {},
   "source": [
    "#### Solar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9b7b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2016 = pd.read_feather(\n",
    "    \"s3://data.atoti.io/notebooks/ca-solar/nsrdb_2016_California_20UTC_GHI.feather\"\n",
    ")\n",
    "data_2016[\"datetime\"] = data_2016[\"datetime\"].dt.tz_localize(\"UTC\")\n",
    "\n",
    "print(f\"Data size: {len(data_2016)}\\n\\n\")\n",
    "data_2016.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8454e604",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2017 = pd.read_feather(\n",
    "    \"s3://data.atoti.io/notebooks/ca-solar/nsrdb_2017_California_20UTC_GHI.feather\"\n",
    ")\n",
    "data_2017[\"datetime\"] = data_2017[\"datetime\"].dt.tz_localize(\"UTC\")\n",
    "\n",
    "print(f\"Data size: {len(data_2017)}\\n\\n\")\n",
    "data_2017.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5bea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2018 = pd.read_feather(\n",
    "    \"s3://data.atoti.io/notebooks/ca-solar/nsrdb_2018_California_20UTC_GHI.feather\"\n",
    ")\n",
    "data_2018[\"datetime\"] = data_2018[\"datetime\"].dt.tz_localize(\"UTC\")\n",
    "\n",
    "print(f\"Data size: {len(data_2018)}\\n\\n\")\n",
    "data_2018.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88ae04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2019 = pd.read_feather(\n",
    "    \"s3://data.atoti.io/notebooks/ca-solar/nsrdb_2019_California_20UTC_GHI.feather\"\n",
    ")\n",
    "data_2019[\"datetime\"] = data_2019[\"datetime\"].dt.tz_localize(\"UTC\")\n",
    "\n",
    "print(f\"Data size: {len(data_2019)}\\n\\n\")\n",
    "data_2019.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c1c96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2020 = pd.read_feather(\n",
    "    \"s3://data.atoti.io/notebooks/ca-solar/nsrdb_2020_California_20UTC_GHI.feather\"\n",
    ")\n",
    "data_2020[\"datetime\"] = data_2020[\"datetime\"].dt.tz_convert(\"UTC\")\n",
    "\n",
    "print(f\"Data size: {len(data_2020)}\\n\\n\")\n",
    "data_2020.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356b0580",
   "metadata": {},
   "source": [
    "### Stations data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9574fbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = pd.read_feather(\n",
    "    \"s3://data.atoti.io/notebooks/ca-solar/nsrdb_station_lat_lon.feather\"\n",
    ")\n",
    "\n",
    "print(f\"Data size: {len(stations)}\\n\\n\")\n",
    "stations.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc68de7",
   "metadata": {},
   "source": [
    "### Fires data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ce3c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_data = pd.read_feather(\"s3://data.atoti.io/notebooks/ca-solar/fire_data.feather\")\n",
    "fire_data[\"StartedDate\"] = (\n",
    "    fire_data[\"StartedDate\"].apply(pd.to_datetime).dt.tz_localize(\"UTC\")\n",
    ")\n",
    "fire_data[\"EndedDate\"] = (\n",
    "    fire_data[\"EndedDate\"].apply(pd.to_datetime).dt.tz_localize(\"UTC\")\n",
    ")\n",
    "\n",
    "print(f\"Data size: {len(fire_data)}\\n\\n\")\n",
    "fire_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cb5340",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_loc = pd.read_feather(\"s3://data.atoti.io/notebooks/ca-solar/fire_loc.feather\")\n",
    "\n",
    "print(f\"Data size: {len(fire_loc)}\\n\\n\")\n",
    "fire_loc.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaaed78",
   "metadata": {},
   "source": [
    "## Station to fire proximity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00cc37f-d1c3-4fde-8aeb-b8f62746874b",
   "metadata": {},
   "source": [
    "#### Running this cell could take many minutes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cc2597-c638-4c0e-af09-0fa8ea65fa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X = fire_loc[[\"Latitude\", \"Longitude\"]]\n",
    "Y = stations[[\"Latitude\", \"Longitude\"]]\n",
    "\n",
    "distances = pairwise_distances(X, Y, metric=custom_distance, n_jobs=-1)\n",
    "\n",
    "print(f\"Distance matrix size: {distances.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0b8336",
   "metadata": {},
   "source": [
    "### Save the distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47956af-8c99-4088-b67f-798e6c3edcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_df = pd.DataFrame(\n",
    "    distances, index=list(fire_loc[\"Fire\"]), columns=list(stations[\"Station\"])\n",
    ")\n",
    "distances_df.to_csv(os.path.join(RESULTS, \"fires-stations-distances.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac57755",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Filter the stations\n",
    "#### For each fire, we consider:\n",
    "#### - Only the stations located under a certain distance (let's consider this distance to be 10 kms here);\n",
    "#### - Only the two closest stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ab028a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fires_names = natsorted(fire_loc.Fire.tolist())\n",
    "stations_names = natsorted(stations.Station.tolist())\n",
    "proximity = 10\n",
    "num_stations_retained = 2\n",
    "\n",
    "fire_stations = retain_stations_per_fire(\n",
    "    fires_names, stations_names, distances, proximity, num_stations_retained\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Number of fires retained (with stations far from less than {proximity} km): {len(fire_stations)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a523bb0",
   "metadata": {},
   "source": [
    "## Filter the stations data\n",
    "\n",
    "#### For each fire, for each retained station (close to the fire), we consider only the data correspind to the period when the fire happened.\n",
    "\n",
    "#### For example, if a fire lasted 2 days, we would consider the data of the concerned stations only for these 2 days."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a22676-28b3-4984-b3b9-9c0708574dfa",
   "metadata": {},
   "source": [
    "#### Running this cell could take many minutes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61a19b0-ce77-44b9-b856-c72606affbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "stations = Parallel(n_jobs=-1, prefer=\"threads\", temp_folder=RESULTS)(\n",
    "    delayed(get_station_data_from_fire_dates)(fire, station)\n",
    "    for fire in fires_samples\n",
    "    for station in fire_stations[fire]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5a3f1b",
   "metadata": {},
   "source": [
    "### Create the dataframe with the selected fires and associated stations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891b8228-4045-4b94-87cd-4eef02eb90d7",
   "metadata": {},
   "source": [
    "#### Running this cell could take many minutes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d162709-6a91-4fa4-94b1-e13bbb9278d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "fires = natsorted(list(fire_stations.keys()))\n",
    "df = pd.DataFrame()\n",
    "lenghts = []  # Number of rows for each fire\n",
    "\n",
    "for fire in fires:\n",
    "    for idx in range(len(fire_stations[fire])):  # for station in fire_stations[fire]:\n",
    "        d = get_station_data_from_fire_dates(\n",
    "            fire, fire_stations[fire][idx]\n",
    "        )  # d = get_station_data_from_fire_dates(fire, station)\n",
    "        d[\"fire\"] = [fire] * len(d)\n",
    "        d[\"station\"] = [\"station_\" + str(idx + 1)] * len(\n",
    "            d\n",
    "        )  # d['station'] = [station] * len(d)\n",
    "        df = pd.concat([df, d])\n",
    "        lenghts.append(len(d))\n",
    "\n",
    "first_cols = [\"fire\", \"station\"]\n",
    "cols = first_cols + [c for c in df.columns if c not in first_cols and c != \"Station\"]\n",
    "df = df[cols].reset_index(drop=True)\n",
    "\n",
    "print(f\"Size of the filtered dataset: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9edd9f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Save the filtered dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1456e6-2450-4b9e-831e-36db73d93876",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(RESULTS, \"fires-stations-filtered-dataset.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195539f1",
   "metadata": {},
   "source": [
    "### Number of stations for each fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de86208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_stations_per_fire = {\n",
    "    fire: len(fire_stations[fire]) for fire in list(fire_stations.keys())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa81ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = list(np.arange(0, 1.1, 0.1))\n",
    "values = list(np.quantile(list(num_stations_per_fire.values()), quantiles))\n",
    "\n",
    "for quantile, value in zip(quantiles, values):\n",
    "    print(f\"Quantile {int(quantile*100)}%: {int(value)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1f0017",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = dict(Counter(list(num_stations_per_fire.values())))\n",
    "dic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c6cafa",
   "metadata": {},
   "source": [
    "So, we have retained 1215 stations fires, and exactly 2 \"clsoe\" stations for each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b610af",
   "metadata": {},
   "source": [
    "### Duration of the fires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c524465",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_duration = list(\n",
    "    fire_data[\"EndedDate\"].apply(pd.to_datetime)\n",
    "    - fire_data[\"StartedDate\"].apply(pd.to_datetime)\n",
    ")\n",
    "fire_duration = [duration.days for duration in fire_duration]\n",
    "\n",
    "values = list(np.quantile(fire_duration, quantiles))\n",
    "\n",
    "print(\"Distribution of the durations of the fires (in days):\\n\")\n",
    "for quantile, value in zip(quantiles, values):\n",
    "    print(f\"Quantile {int(quantile*100)}%: {int(value)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cc0089",
   "metadata": {},
   "source": [
    "### Reload the fires and stations data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef91c04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(RESULTS, \"fires-stations-filtered-dataset.csv\"))\n",
    "\n",
    "print(f\"Size of the data: {df.shape}\\n\\n\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a7e22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accres_burnt = list(fire_data[\"AcresBurned\"])\n",
    "quantiles = list(np.arange(0, 1.01, 0.01))\n",
    "values = list(np.quantile(accres_burnt, quantiles))\n",
    "\n",
    "print(\"Distribution of the acres burnt:\\n\")\n",
    "for quantile, value in zip(quantiles, values):\n",
    "    print(f\"Quantile {int(quantile*100)}%: {int(value)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4646789",
   "metadata": {},
   "source": [
    "## Hypotheses:\n",
    "\n",
    "#### We consider:\n",
    "#### - The fires with surrounding stations far from at most 10 kms;\n",
    "#### - The fires with at least two stations within 10 kms distance;\n",
    "#### - The fires that lasted at most 120 days (4 months)\n",
    "#### - Two sattions excatly, for each fire retained. We choose the two closest ones in case there are more than two stations;\n",
    "#### - The threshold of 10 000 acres burnt to categorize the fires: class -1 corresponds to fires that burnt less than 10 000 acres, class 1 to the others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1267993",
   "metadata": {},
   "source": [
    "### Filter the fires and add their category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b718313",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_duration = 120  # 4 months\n",
    "acres_burnt_threshold = 10000\n",
    "\n",
    "fires_retained = fire_data.copy()\n",
    "fires_retained[\"EndedDate\"] = fires_retained[\"EndedDate\"].apply(pd.to_datetime)\n",
    "fires_retained[\"StartedDate\"] = fires_retained[\"StartedDate\"].apply(pd.to_datetime)\n",
    "fires_retained[\"duration_in_days\"] = list(\n",
    "    fires_retained[\"EndedDate\"] - fires_retained[\"StartedDate\"]\n",
    ")\n",
    "fires_retained[\"duration_in_days\"] = [\n",
    "    duration.days for duration in list(fires_retained[\"duration_in_days\"])\n",
    "]\n",
    "fires_retained = fires_retained[fires_retained[\"duration_in_days\"] <= max_duration]\n",
    "fires_retained[\"category\"] = fires_retained[\"AcresBurned\"].apply(\n",
    "    lambda x: \"-1\" if x < acres_burnt_threshold else \"1\"\n",
    ")\n",
    "fires_retained = fires_retained[fires_retained[\"Fire\"].isin(list(fire_stations.keys()))]\n",
    "\n",
    "print(f\"Number of fires retained: {len(fires_retained)}\\n\\n\")\n",
    "fires_retained.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a0cc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "acres_burnt_and_caterogies = {\n",
    "    fire: {\"acres_burnt\": acres_burnt, \"category\": category}\n",
    "    for fire, acres_burnt, category in zip(\n",
    "        list(fires_retained[\"Fire\"]),\n",
    "        list(fires_retained[\"AcresBurned\"]),\n",
    "        list(fires_retained[\"category\"]),\n",
    "    )\n",
    "}\n",
    "for k in random.sample(list(acres_burnt_and_caterogies.keys()), 5):\n",
    "    print(f\"{k}: {acres_burnt_and_caterogies[k]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d672c7",
   "metadata": {},
   "source": [
    "### Add the number of acres burnt and the category of the fire for each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21469ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = df[df[\"fire\"].isin(set(fires_retained[\"Fire\"]))]\n",
    "df = add_fire_crticity(df, acres_burnt_and_caterogies)\n",
    "df = add_fire_duration(df)\n",
    "\n",
    "print(f\"Size of the data: {len(df)}\\n\\n\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0909a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e94c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3d258d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"category\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d25085",
   "metadata": {},
   "source": [
    "## Save the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5074394e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(RESULTS, \"fires-stations-final-dataset.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.4xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
