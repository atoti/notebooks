{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4054057c",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "\n",
    "### In this notebook, we roll the datasets for the later features extraction.\n",
    "\n",
    "### To achieve this, we use the tsfresh library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93ce4bc",
   "metadata": {},
   "source": [
    "### Install some required packages\n",
    "#### Please install just those that are not yet installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e3ead2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install natsort\n",
    "!pip install tsfresh\n",
    "!pip install pandas-profiling\n",
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fd1fff",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3422a8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import pandas as pd, numpy as np\n",
    "import random\n",
    "from natsort import natsorted\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import datetime\n",
    "from datetime import date, timedelta\n",
    "import time\n",
    "\n",
    "from tsfresh import extract_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import (\n",
    "    impute,\n",
    "    make_forecasting_frame,\n",
    "    roll_time_series,\n",
    ")\n",
    "from tsfresh.feature_extraction import (\n",
    "    ComprehensiveFCParameters,\n",
    "    EfficientFCParameters,\n",
    "    MinimalFCParameters,\n",
    "    settings,\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from pandas_profiling import ProfileReport\n",
    "from collections import Counter\n",
    "import ast\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d458520",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cpus = multiprocessing.cpu_count()\n",
    "\n",
    "print(f\"Number of available cpus: {multiprocessing.cpu_count()}\\n\")\n",
    "print(f\"Number of cpus to use: {num_cpus}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d949b7d",
   "metadata": {},
   "source": [
    "### Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2782e4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS = \"../results\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5623d4",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7113b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_input_format_1(input_dataset):\n",
    "    \"\"\"\n",
    "    Change the format of the data to tsfresh input format 1.\n",
    "\n",
    "    Arguments:\n",
    "        df: the dataframe to be transformed\n",
    "\n",
    "    Return:\n",
    "        The dataframe transformed to tsfresh input format 1.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    fires = natsorted(list(np.unique(input_dataset.fire)))\n",
    "    stations = natsorted(list(np.unique(input_dataset.station)))\n",
    "\n",
    "    for fire in fires:\n",
    "        df_temp = pd.DataFrame()\n",
    "        for station in stations:\n",
    "            reduced_df = data[(data[\"fire\"] == fire) & (data[\"station\"] == station)]\n",
    "            reduced_df = reduced_df.sort_values(\"datetime\").reset_index(drop=True)\n",
    "\n",
    "            if station == \"station_1\":\n",
    "                df_temp[\"fire\"] = [fire] * len(reduced_df)\n",
    "                df_temp[\"time_step\"] = reduced_df[\"duration_in_hours\"].copy()\n",
    "                df_temp[\"acres_burnt\"] = reduced_df[\"acres_burnt\"].copy()\n",
    "                df_temp[\"duration_in_hours\"] = reduced_df[\"duration_in_hours\"].copy()\n",
    "                df_temp[\"category\"] = reduced_df[\"category\"].copy()\n",
    "\n",
    "            remove_cols = [\"station\"]\n",
    "            common_cols = [\n",
    "                \"fire\",\n",
    "                \"datetime\",\n",
    "                \"acres_burnt\",\n",
    "                \"duration_in_hours\",\n",
    "                \"category\",\n",
    "            ]\n",
    "            other_cols = [\n",
    "                c\n",
    "                for c in reduced_df.columns\n",
    "                if c not in remove_cols and c not in common_cols\n",
    "            ]\n",
    "            reduced_df = reduced_df[other_cols]\n",
    "            reduced_df = reduced_df.rename(\n",
    "                columns={\n",
    "                    \"ghi\": \"ghi_\" + station,\n",
    "                    \"dni\": \"dni_\" + station,\n",
    "                    \"wind_speed\": \"wind_speed_\" + station,\n",
    "                    \"wind_direction\": \"wind_direction_\" + station,\n",
    "                    \"dhi\": \"dhi_\" + station,\n",
    "                    \"air_temperature\": \"air_temperature_\" + station,\n",
    "                    \"solar_zenith_angle\": \"solar_zenith_angle_\" + station,\n",
    "                }\n",
    "            )\n",
    "            df_temp = pd.concat([df_temp, reduced_df], axis=1)\n",
    "        ordered_cols = (\n",
    "            [\"fire\", \"time_step\"]\n",
    "            + [\n",
    "                c\n",
    "                for c in df_temp.columns\n",
    "                if c\n",
    "                not in [\n",
    "                    \"fire\",\n",
    "                    \"time_step\",\n",
    "                    \"acres_burnt\",\n",
    "                    \"duration_in_hours\",\n",
    "                    \"category\",\n",
    "                ]\n",
    "            ]\n",
    "            + [\"acres_burnt\", \"duration_in_hours\", \"category\"]\n",
    "        )\n",
    "        df_temp = df_temp[ordered_cols]\n",
    "        df = pd.concat([df, df_temp])\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eec6b23",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a2cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(RESULTS, \"fires-stations-final-dataset.csv\"))\n",
    "\n",
    "print(f\"Size of the data: {data.shape}\\n\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a6176b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# STEP 0: Prepare the data\n",
    "\n",
    "### We reformat the data to put it into tsfresh data format 1. This is necessary for the later creation of the forecasting dataframe using the tsfresh native function *make_forecasting_frame()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6cf119",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data = transform_to_input_format_1(data)\n",
    "\n",
    "print(f\"Size of the data: {data.shape}\\n\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b406bec6",
   "metadata": {},
   "source": [
    "### Save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93671ff5-ec6d-4030-88ef-a91723a29b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\n",
    "    os.path.join(RESULTS, \"fires-stations-final-dataset-flat-format.csv\"), index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4db472",
   "metadata": {},
   "source": [
    "# STEP 1: Quick EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60123b8a-92ad-4bb5-8f85-cc6ef7ae6a26",
   "metadata": {},
   "source": [
    "#### Running this cell could take many minutes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b62e33-579b-4d1b-b62f-0c303efa69cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(data, title=\"Data exploration - Pandas Profiling Report\")\n",
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d96940",
   "metadata": {},
   "source": [
    "# STEP 2: Train / val / test split \n",
    "### We split the data based on their date of occurrence, as follows:\n",
    "### - We consider the earliest dated fires to train the model, and the most recent ones to test it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b61a47",
   "metadata": {},
   "source": [
    "#### Load the fires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec33e6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_data = pd.read_feather(\"s3://data.atoti.io/notebooks/ca-solar/fire_data.feather\")\n",
    "fire_data[\"StartedDate\"] = (\n",
    "    fire_data[\"StartedDate\"].apply(pd.to_datetime).dt.tz_localize(\"UTC\")\n",
    ")\n",
    "fire_data[\"EndedDate\"] = (\n",
    "    fire_data[\"EndedDate\"].apply(pd.to_datetime).dt.tz_localize(\"UTC\")\n",
    ")\n",
    "\n",
    "print(f\"Data size: {len(fire_data)}\\n\\n\")\n",
    "fire_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c22fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_data = (\n",
    "    fire_data[fire_data[\"Fire\"].isin(list(data.fire))]\n",
    "    .sort_values(\"EndedDate\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(f\"Data size: {len(fire_data)}\\n\\n\")\n",
    "fire_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59063a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d141185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we consider 85% of the fires for training\n",
    "# we choose the earlier dates\n",
    "train_fires = list(fire_data.Fire)[: int(0.85 * len(fire_data))]\n",
    "valtest_fires = [fire for fire in list(fire_data.Fire) if fire not in train_fires]\n",
    "# we keep the raimining 15% of the fires for validation and testing (the most recent dates)\n",
    "# then, we consider a 50%-50% distribution for validation and  testing (hold-out) respectively\n",
    "val_fires = valtest_fires[: int(0.5 * len(valtest_fires))]\n",
    "test_fires = [fire for fire in valtest_fires if fire not in val_fires]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c5f1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_data[fire_data[\"Fire\"].isin(train_fires)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f5f5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_data[fire_data[\"Fire\"].isin(val_fires)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b6f992",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_data[fire_data[\"Fire\"].isin(test_fires)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21833233",
   "metadata": {},
   "source": [
    "### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abc9757",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data[data[\"fire\"].isin(train_fires)].reset_index(drop=True)\n",
    "\n",
    "print(f\"Size of the train data: {len(data_train)}\\n\\n\")\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27912cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = data[data[\"fire\"].isin(val_fires)].reset_index(drop=True)\n",
    "\n",
    "print(f\"Size of the train data: {len(data_val)}\\n\\n\")\n",
    "data_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f647aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data[data[\"fire\"].isin(test_fires)].reset_index(drop=True)\n",
    "\n",
    "print(f\"Size of the train data: {len(data_test)}\\n\\n\")\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f816f5",
   "metadata": {},
   "source": [
    "### Save the raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefe56ab-bfa6-4bfc-a909-ac7685a6bc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.to_csv(\n",
    "    os.path.join(RESULTS, \"fires-stations-final-dataset-flat-format_train.csv\"),\n",
    "    index=False,\n",
    ")\n",
    "data_val.to_csv(\n",
    "    os.path.join(RESULTS, \"fires-stations-final-dataset-flat-format_val.csv\"),\n",
    "    index=False,\n",
    ")\n",
    "data_test.to_csv(\n",
    "    os.path.join(RESULTS, \"fires-stations-final-dataset-flat-format_test.csv\"),\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03521d5",
   "metadata": {},
   "source": [
    "### Check the distribution of the classes in the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adda807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.category.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8dfd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val.category.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d20fbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.category.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4923e85d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### We can observe that the critical fires (calss 1) happened more frequently (in proportion) in the recent period, between Aug 2020 and Jan 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e1fe77",
   "metadata": {},
   "source": [
    "# STEP 3: Roll the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28843c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_rolled_train = roll_time_series(\n",
    "    data_train,\n",
    "    column_id=\"fire\",\n",
    "    column_sort=\"time_step\",\n",
    "    rolling_direction=1,\n",
    "    max_timeshift=11,\n",
    "    min_timeshift=3,\n",
    "    n_jobs=num_cpus,\n",
    ")\n",
    "df_rolled_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8917d1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rolled_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70066b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_rolled_val = roll_time_series(\n",
    "    data_val,\n",
    "    column_id=\"fire\",\n",
    "    column_sort=\"time_step\",\n",
    "    rolling_direction=1,\n",
    "    max_timeshift=11,\n",
    "    min_timeshift=3,\n",
    "    n_jobs=num_cpus,\n",
    ")\n",
    "df_rolled_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68f2f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rolled_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be3bfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_rolled_test = roll_time_series(\n",
    "    data_test,\n",
    "    column_id=\"fire\",\n",
    "    column_sort=\"time_step\",\n",
    "    rolling_direction=1,\n",
    "    max_timeshift=11,\n",
    "    min_timeshift=3,\n",
    "    n_jobs=num_cpus,\n",
    ")\n",
    "df_rolled_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b02da78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rolled_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac55f586",
   "metadata": {},
   "source": [
    "### Save the rolled datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7fcb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rolled_train.to_csv(\n",
    "    os.path.join(RESULTS, \"fires-stations-final-dataset-flat-format-rolled-train.csv\"),\n",
    "    index=False,\n",
    ")\n",
    "df_rolled_val.to_csv(\n",
    "    os.path.join(RESULTS, \"fires-stations-final-dataset-flat-format-rolled-val\"),\n",
    "    index=False,\n",
    ")\n",
    "df_rolled_test.to_csv(\n",
    "    os.path.join(RESULTS, \"fires-stations-final-dataset-flat-format-rolled-test.csv\"),\n",
    "    index=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.c5.24xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
