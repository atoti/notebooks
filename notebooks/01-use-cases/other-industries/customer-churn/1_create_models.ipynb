{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telco Customer Churn - Create models\n",
    "\n",
    "In this notebook, we will look at the customer churn in the telecommunication sector.  \n",
    "Using the [Telco Customer Churn data](https://www.kaggle.com/blastchar/telco-customer-churn) from Kaggle, we explore the accuracy of 4 machine learning algorithms against the actual churn in the past month:  \n",
    "- Dummy Prediction\n",
    "- Logistic Regression Prediction\n",
    "- Naive Bayes Prediction\n",
    "- SVM Classifier Linear Prediction\n",
    "\n",
    "Note: we train the models with last month's churn data using the algorithm provided in [Telecom Customer Churn Prediction](https://www.kaggle.com/pavanraj159/telecom-customer-churn-prediction)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to install\n",
    "pip install imblearn  \n",
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use imblearn if you would like to use a SMOTE approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install -c numba/label/dev numba\n",
    "# !pip install pandas_profiling imblearn sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import pandas as pd\n",
    "import wget\n",
    "from _utils import data_utils, prediction\n",
    "from IPython.display import clear_output, display\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = \"./output/\"\n",
    "MODELS_PATH = \"./models/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data download\n",
    "\n",
    "Skip the following step if you already have the output data from [0_prepare_data.ipynb](0_prepare_data.ipynb) or downloaded the output data previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_custom(current, total, width=80):\n",
    "    clear_output(wait=True)\n",
    "    print(\"Downloading: %d%% [%d / %d] bytes\" % (current / total * 100, current, total))\n",
    "\n",
    "\n",
    "output_url = \"https://data.atoti.io/notebooks/telco-churn/output.zip\"\n",
    "wget.download(output_url, bar=bar_custom)\n",
    "\n",
    "with ZipFile(\"output.zip\", \"r\") as zipObj:\n",
    "    # Extract all the contents of zip file in current directory\n",
    "    zipObj.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1: Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "binary_df = pd.read_csv(os.path.join(OUTPUT_PATH, \"all_df.csv\"))\n",
    "train_df_transf = pd.read_csv(os.path.join(OUTPUT_PATH, \"train_df_transf.csv\"))\n",
    "test_df_transf = pd.read_csv(os.path.join(OUTPUT_PATH, \"test_df_transf.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>...</th>\n",
       "      <th>PaymentMethod_Mailed check</th>\n",
       "      <th>TenureGroup_Tenure_12-24</th>\n",
       "      <th>TenureGroup_Tenure_24-48</th>\n",
       "      <th>TenureGroup_Tenure_48-60</th>\n",
       "      <th>TenureGroup_Tenure_gt_60</th>\n",
       "      <th>Subset_Train</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Subset_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6429-SHBCB</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.548343</td>\n",
       "      <td>0.159854</td>\n",
       "      <td>-0.393491</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0810-DHDBD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.794776</td>\n",
       "      <td>0.306400</td>\n",
       "      <td>0.701293</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4471-KXAUH</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.387770</td>\n",
       "      <td>0.649451</td>\n",
       "      <td>0.573764</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4868-AADLV</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.364584</td>\n",
       "      <td>1.713576</td>\n",
       "      <td>2.458080</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6478-HRRCZ</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.019235</td>\n",
       "      <td>0.189829</td>\n",
       "      <td>-0.037602</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  Gender  SeniorCitizen  Partner  Dependents  PhoneService  \\\n",
       "0  6429-SHBCB       1              0        0           0             1   \n",
       "1  0810-DHDBD       0              0        0           0             1   \n",
       "2  4471-KXAUH       0              0        1           0             1   \n",
       "3  4868-AADLV       1              1        1           1             1   \n",
       "4  6478-HRRCZ       1              0        1           0             1   \n",
       "\n",
       "   OnlineSecurity  OnlineBackup  DeviceProtection  TechSupport  ...  \\\n",
       "0               0             0                 0            0  ...   \n",
       "1               1             0                 1            1  ...   \n",
       "2               0             0                 1            1  ...   \n",
       "3               1             1                 1            1  ...   \n",
       "4               1             1                 0            1  ...   \n",
       "\n",
       "   PaymentMethod_Mailed check  TenureGroup_Tenure_12-24  \\\n",
       "0                           1                         1   \n",
       "1                           0                         0   \n",
       "2                           0                         0   \n",
       "3                           0                         0   \n",
       "4                           1                         0   \n",
       "\n",
       "   TenureGroup_Tenure_24-48  TenureGroup_Tenure_48-60  \\\n",
       "0                         0                         0   \n",
       "1                         0                         1   \n",
       "2                         1                         0   \n",
       "3                         0                         0   \n",
       "4                         1                         0   \n",
       "\n",
       "   TenureGroup_Tenure_gt_60  Subset_Train    Tenure  MonthlyCharges  \\\n",
       "0                         0           1.0 -0.548343        0.159854   \n",
       "1                         0           1.0  0.794776        0.306400   \n",
       "2                         0           1.0  0.387770        0.649451   \n",
       "3                         1           1.0  1.364584        1.713576   \n",
       "4                         0           1.0 -0.019235        0.189829   \n",
       "\n",
       "   TotalCharges  Subset_Test  \n",
       "0     -0.393491          NaN  \n",
       "1      0.701293          NaN  \n",
       "2      0.573764          NaN  \n",
       "3      2.458080          NaN  \n",
       "4     -0.037602          NaN  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a few new columns in preparation for the machine learning output.  \n",
    "In the actual churn data, `ChurnProbability` is fixed as the customers have already churned. Hence we gave the probability a value 1.  \n",
    "The `ChurnPredicted` would be the actual churn in this base use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [c for c in train_df_transf.columns if c != \"Churn\"]\n",
    "target_col = \"Churn\"\n",
    "\n",
    "train_X = train_df_transf[cols]\n",
    "train_Y = train_df_transf[target_col]\n",
    "\n",
    "test_X = test_df_transf[cols]\n",
    "test_Y = test_df_transf[target_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2: Modelling\n",
    "\n",
    "You can expand the below sections to look at how we train the models below. As we referenced the algorithm, we will not explained it further. Our purpose is to analyse the prediction and its impact on the telco churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create models\n",
    "Here, we build the models to be compared in the latter part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummy Model - Uniform\n",
    "This model predicts churn randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "DummyClassifier(strategy='uniform')\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.56      0.66       256\n",
      "           1       0.35      0.61      0.44        96\n",
      "\n",
      "    accuracy                           0.58       352\n",
      "   macro avg       0.57      0.59      0.55       352\n",
      "weighted avg       0.67      0.58      0.60       352\n",
      "\n",
      "F1 score:  0.44\n",
      "ROC AUC:  0.59 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dummy_unif_clf = DummyClassifier(strategy=\"uniform\")\n",
    "dummy_unif_clf.fit(train_X, train_Y)\n",
    "\n",
    "dummy_unif_clf = prediction.churn_prediction(\n",
    "    dummy_unif_clf,\n",
    "    test_X,\n",
    "    test_Y,\n",
    "    train_X.columns,\n",
    "    \"features\",\n",
    "    threshold_plot=True,\n",
    "    coefs_or_features=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(MODELS_PATH, \"dummy_unif_clf.sav\")\n",
    "pickle.dump(dummy_unif_clf, open(filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummy Model - Stratified\n",
    "This model predicts churn by respecting the training setâ€™s class distribution   \n",
    "Enable this if you'd like to try a different dummy model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dummy_strat_clf = DummyClassifier(strategy=\"stratified\")\n",
    "dummy_strat_clf.fit(train_X, train_Y)\n",
    "\n",
    "dummy_strat_clf = prediction.churn_prediction(\n",
    "    dummy_strat_clf,\n",
    "    test_X,\n",
    "    test_Y,\n",
    "    train_X.columns,\n",
    "    \"coefficients\",\n",
    "    threshold_plot=True,\n",
    "    coefs_or_features=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model to disk"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "filename = os.path.join(MODELS_PATH, \"dummy_strat_clf.sav\")\n",
    "pickle.dump(dummy_strat_clf, open(filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummy Model - Most frequent\n",
    "This model predicts the majority class (the most frequent label in the training set) all the time  \n",
    "Enable this if you'd like to try a different dummy model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dummy_major_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_major_clf.fit(train_X, train_Y)\n",
    "\n",
    "dummy_major_clf = prediction.churn_prediction(\n",
    "    dummy_major_clf,\n",
    "    test_X,\n",
    "    test_Y,\n",
    "    train_X.columns,\n",
    "    \"coefficients\",\n",
    "    threshold_plot=True,\n",
    "    coefs_or_features=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model to disk"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "filename = os.path.join(MODELS_PATH, \"dummy_major_clf.sav\")\n",
    "pickle.dump(dummy_major_clf, open(filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Model\n",
    "\n",
    "Gaussian Naive Bayes algorithm can be used with the hypothesis that features are independent from each other and their distribution being Gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "GaussianNB()\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87       256\n",
      "           1       0.66      0.58      0.62        96\n",
      "\n",
      "    accuracy                           0.80       352\n",
      "   macro avg       0.75      0.74      0.74       352\n",
      "weighted avg       0.80      0.80      0.80       352\n",
      "\n",
      "F1 score:  0.62\n",
      "ROC AUC:  0.74 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb_clf = GaussianNB()\n",
    "gnb_clf.fit(train_X, train_Y.values.ravel())\n",
    "\n",
    "gnb_clf = prediction.churn_prediction(\n",
    "    gnb_clf,\n",
    "    test_X,\n",
    "    test_Y,\n",
    "    train_X.columns,\n",
    "    \"coefficients\",\n",
    "    threshold_plot=True,\n",
    "    coefs_or_features=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(MODELS_PATH, \"gnb_clf.sav\")\n",
    "pickle.dump(gnb_clf, open(filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "LogisticRegression(C=0.1, class_weight={0: 1, 1: 1.5}, random_state=0,\n",
      "                   solver='newton-cg')\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87       256\n",
      "           1       0.67      0.62      0.65        96\n",
      "\n",
      "    accuracy                           0.81       352\n",
      "   macro avg       0.76      0.75      0.76       352\n",
      "weighted avg       0.81      0.81      0.81       352\n",
      "\n",
      "F1 score:  0.65\n",
      "ROC AUC:  0.75 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "estimator = LogisticRegression()\n",
    "\n",
    "params_grid = {\n",
    "    \"penalty\": [\"l2\"],\n",
    "    \"C\": [0.1, 0.5, 1.0, 5, 10],\n",
    "    \"solver\": [\"liblinear\", \"newton-cg\", \"lbfgs\"],\n",
    "    \"class_weight\": [\n",
    "        \"balanced\",\n",
    "        None,\n",
    "        {0: 1, 1: 1.5},\n",
    "        {0: 1, 1: 2},\n",
    "        {0: 1, 1: 3},\n",
    "        {0: 1, 1: 5},\n",
    "    ],\n",
    "    \"random_state\": [0],\n",
    "}\n",
    "\n",
    "lr_clf = GridSearchCV(\n",
    "    estimator=estimator, param_grid=params_grid, scoring=\"roc_auc\", n_jobs=-1, cv=10\n",
    ")\n",
    "\n",
    "lr_clf.fit(train_X, train_Y.values.ravel())\n",
    "\n",
    "lr_clf = lr_clf.best_estimator_\n",
    "\n",
    "lr_clf = prediction.churn_prediction(\n",
    "    lr_clf,\n",
    "    test_X,\n",
    "    test_Y,\n",
    "    train_X.columns,\n",
    "    \"coefficients\",\n",
    "    threshold_plot=True,\n",
    "    coefs_or_features=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(MODELS_PATH, \"lr_clf.sav\")\n",
    "pickle.dump(lr_clf, open(filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM Classifier Linear Model\n",
    "\n",
    "**That cell will take a few minutes to run!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "SVC(C=0.1, class_weight='balanced', gamma='auto', kernel='linear',\n",
      "    probability=True)\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.75      0.81       256\n",
      "           1       0.53      0.76      0.62        96\n",
      "\n",
      "    accuracy                           0.75       352\n",
      "   macro avg       0.71      0.75      0.72       352\n",
      "weighted avg       0.79      0.75      0.76       352\n",
      "\n",
      "F1 score:  0.62\n",
      "ROC AUC:  0.75 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "estimator = SVC()\n",
    "\n",
    "params_grid = {\n",
    "    \"C\": [0.1, 0.5, 1.0, 5],\n",
    "    \"kernel\": [\"linear\", \"rbf\"],\n",
    "    \"gamma\": [\"auto\", \"scale\"],\n",
    "    \"class_weight\": [\n",
    "        \"balanced\",\n",
    "        None,\n",
    "        {0: 1, 1: 2},\n",
    "        {0: 1, 1: 3},\n",
    "        {0: 1, 1: 5},\n",
    "    ],\n",
    "    \"probability\": [True],\n",
    "}\n",
    "\n",
    "svc_clf = GridSearchCV(\n",
    "    estimator=estimator, param_grid=params_grid, scoring=\"roc_auc\", n_jobs=-1, cv=10\n",
    ")\n",
    "\n",
    "svc_clf.fit(train_X, train_Y.values.ravel())\n",
    "\n",
    "svc_clf = svc_clf.best_estimator_\n",
    "\n",
    "svc_clf = prediction.churn_prediction(\n",
    "    svc_clf,\n",
    "    test_X,\n",
    "    test_Y,\n",
    "    train_X.columns,\n",
    "    \"coefficients\",\n",
    "    threshold_plot=False,\n",
    "    coefs_or_features=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(MODELS_PATH, \"svc_clf.sav\")\n",
    "pickle.dump(svc_clf, open(filename, \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
