{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5138d3c8-8fbb-4556-9730-e490f0dcabe3",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to download data from the \n",
    "The National Renewable Energy Laboratory (NREL) \n",
    "Solar Radiation Database (NSRDB).\n",
    "\n",
    "For this to work, first install h5pyd:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "45df2ddc-8694-40aa-a70e-684ac94abe25",
   "metadata": {},
   "source": [
    "$ pip3 install --user h5pyd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b2442b-eabc-4a57-99c9-ef809f55a8ab",
   "metadata": {},
   "source": [
    "Next, configure HSDS: (in shell)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bfa7fbdf-1625-4e13-aeb9-a651e2fe9370",
   "metadata": {},
   "source": [
    "$ hsconfigure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2a8711-8600-45e7-89f5-b66e135396ad",
   "metadata": {},
   "source": [
    "and enter at the prompt:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f1c8414d-292f-446a-b608-87561e7c4c7c",
   "metadata": {},
   "source": [
    "hs_endpoint = https://developer.nrel.gov/api/hsds\n",
    "hs_username = None\n",
    "hs_password = None\n",
    "hs_api_key = 3K3JQbjZmWctY0xmIfSYvYgtIcM3CN0cb1Y2w9bf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ef38f0-ffea-4396-9b3f-c5c1e51f8840",
   "metadata": {},
   "source": [
    "This notebook draws heavily from NREL github examples (https://github.com/NREL/hsds-examples/blob/master/notebooks/) and uses the example API key given there. Used here is the demonstation key and is rate-limited per IP.\n",
    "\n",
    "To get an API key, visit https://developer.nrel.gov/signup/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4474add-d3a3-4eac-806a-15309cdec4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "import h5pyd  # to read from nrel server\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.feather as feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c917b6-2219-41c7-ad82-01f6689dcf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_missing(lst):\n",
    "    return [x for x in range(lst[0], lst[-1] + 1) if x not in lst]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952e3bf6-523a-4342-bd43-78a269a39c21",
   "metadata": {},
   "source": [
    "While the wildfires are primarily located in California, winds and the jet stream means the smoke from a California fire can also impact neighboring states.  This and the next file are structured so GHI data for other states can just as easily be downloaded and studied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b483da-767d-470b-af47-472d6a989311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set state, year, time of day to download\n",
    "state = \"California\"\n",
    "start = 2016\n",
    "end = 2021\n",
    "utctime = \"20\"  # selecting noon local standard time\n",
    "k = 3  # keeping only 1/k^2 of the locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76698886-a3e1-4aa4-819c-5b0a6051f4c8",
   "metadata": {},
   "source": [
    "Connect to the NREL server to download the meta-data for the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a5de83-e200-4423-923a-2e26fe4c2739",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_path = f\"/nrel/nsrdb/v3/nsrdb_{start}.h5\"\n",
    "with h5pyd.File(remote_path, mode=\"r\") as f:\n",
    "    meta = pd.DataFrame(f[\"meta\"][...])\n",
    "    meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf3975d-104b-4a73-b060-e390f0de9216",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_meta = meta.loc[meta[\"state\"] == bytes(state, encoding=\"utf-8\")]\n",
    "state_index = state_meta.index.values.copy()\n",
    "print(f\"Number of NSRDB pixels in {state} = {len(state_meta)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a4519b-0ec3-4004-a24b-fcb5c1a2fc26",
   "metadata": {},
   "source": [
    "Create a dateframe of the sensor station locations in latitude and longitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49695a2e-7c49-4ea6-9078-c07a16fbabdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "latlon_data = []\n",
    "for index in state_index:\n",
    "    location_id = f\"station_{index:0=9d}\"\n",
    "    location_data = [location_id, meta[\"latitude\"][index], meta[\"longitude\"][index]]\n",
    "    latlon_data.append(location_data)\n",
    "\n",
    "latlon_df = pd.DataFrame(latlon_data, columns=[\"Station\", \"Latitude\", \"Longitude\"])\n",
    "latlon_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa520a4-bfe2-402d-a80f-2849d1308e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = sorted(latlon_df.Latitude.unique())\n",
    "lon = sorted(latlon_df.Longitude.unique())\n",
    "\n",
    "# keeping only 1/k^2 of the station data\n",
    "keep_lats = lat[::k]\n",
    "keep_lons = lon[::k]\n",
    "\n",
    "final_latlon = latlon_df[\n",
    "    latlon_df[\"Latitude\"].isin(keep_lats) & latlon_df[\"Longitude\"].isin(keep_lons)\n",
    "]\n",
    "\n",
    "feather.write_feather(final_latlon, f\"./data/nsrdb_station_lat_lon.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cf7459-e92c-4ced-becd-d28a367cd773",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(start, end):\n",
    "    # Set remote destination of h5 file from nrel\n",
    "    file_path = \"/nrel/nsrdb/v3/nsrdb_{}.h5\".format(year)\n",
    "    with h5pyd.File(file_path, mode=\"r\") as f:\n",
    "        # create time indices for dataframe\n",
    "        time_df = pd.DataFrame()\n",
    "        time_df[\"datetime\"] = pd.to_datetime(f[\"time_index\"][::2].astype(str))\n",
    "        time_df[\"time\"] = [d.time() for d in time_df[\"datetime\"]]\n",
    "\n",
    "        # for each type of data (https://nsrdb.nrel.gov/about/u-s-data.html)\n",
    "        for dset in [\n",
    "            \"ghi\"\n",
    "        ]:  # ['dni', 'wind_speed', 'wind_direction', 'dhi', 'air_temperature', 'solar_zenith_angle']:\n",
    "            # access the nsrdb h5 file\n",
    "            ds = f[dset]\n",
    "            state_df = pd.DataFrame()\n",
    "\n",
    "            # create numpy superset array containing all columns for current state\n",
    "            lower_bound = state_index[0]\n",
    "            upper_bound = state_index[-1]\n",
    "            supset = (\n",
    "                ds[::2, lower_bound : upper_bound + 1] / ds.attrs[\"psm_scale_factor\"]\n",
    "            )  # ::2 ---> hourly data only\n",
    "\n",
    "            # Determine which columns to remove from superset of columns\n",
    "            offset = state_index[0]\n",
    "            state_list = [x - offset for x in state_index]\n",
    "            remove_indices = find_missing(state_list)\n",
    "            state_data = np.delete(supset, remove_indices, 1)\n",
    "\n",
    "            # Add station labels to data\n",
    "            count = 0\n",
    "            for index in state_index:\n",
    "                location_id = f\"station_{index:0=9d}\"\n",
    "                state_df[location_id] = state_data[:, count]\n",
    "                count += 1\n",
    "\n",
    "            # concatenate state data with timeseries indices\n",
    "            time_state_df = pd.concat([time_df, state_df], axis=1)\n",
    "\n",
    "            # removing all data except specified UTC time\n",
    "            state_noon_data = time_state_df[\n",
    "                time_state_df[\"time\"].astype(str).isin([utctime + \":00:00\"])\n",
    "            ]\n",
    "            del state_noon_data[\"time\"]\n",
    "\n",
    "            # reshape data to columnar df\n",
    "            melted_state_df = pd.melt(\n",
    "                state_noon_data,\n",
    "                id_vars=[\"datetime\"],\n",
    "                var_name=\"Station\",\n",
    "                value_name=dset,\n",
    "            )\n",
    "\n",
    "            final_state_df = melted_state_df[\n",
    "                melted_state_df[\"Station\"].isin(final_latlon[\"Station\"])\n",
    "            ]\n",
    "\n",
    "            feather.write_feather(\n",
    "                final_state_df, f\"./data/nsrdb_{year}_{state}_{utctime}UTC_GHI.feather\"\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
